{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "import scipy.io as sio\n",
    "\n",
    "from vehicle_model_variant import Environment \n",
    "from cell_model import CellModel \n",
    "from driver_MDP import Driver_MDP \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "# env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "driver = Driver_MDP(0.02)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 150\n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1.0 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(weights_root=None): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "    if weights_root is not None:     \n",
    "        print(\"model is loaded on {}\".format(weights_root))\n",
    "        actor_model.load_weights(\"./{}/actor_model.h5\".format(weights_root))\n",
    "        critic_model.load_weights(\"./{}/critic_model.h5\".format(weights_root))\n",
    "        target_actor.load_weights(\"./{}/target_actor.h5\".format(weights_root))\n",
    "        target_critic.load_weights(\"./{}/target_critic.h5\".format(weights_root))\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    if not os.path.exists(root): \n",
    "        os.makedirs(root)\n",
    "        \n",
    "    actor_model.save_weights(\"./{}/actor_model.h5\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model.h5\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor.h5\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic.h5\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor, consider_degradation):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor, consider_degradation)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor, consider_degradation):\n",
    "    test_cycle = driver.get_cycle() \n",
    "    env = initialization_env(test_cycle, reward_factor, consider_degradation)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    degradation_total = np.sum(np.array(env.history[\"degradation\"])) \n",
    "    print(\"******************* Test is start *****************\")\n",
    "#     print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "        \"SOC: {:.4f}\".format(env.SOC), \n",
    "        \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "        \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        \"Degradation total: {:.4f}\".format(degradation_total))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(test_cycle)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(env.history[\"Action\"])\n",
    "    plt.show() \n",
    "    return env.history  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_reward_factor(reward_factor_temp, result_dict, thresh): \n",
    "    histories = result_dict[\"train_history\"]\n",
    "    SOCs = [env_history[\"SOC\"][-1] for env_history in histories] \n",
    "#     SOCs = result_dict[\"SOCs\"]\n",
    "    SOC_at_equilibrium = np.mean(SOCs[-10:])\n",
    "    if abs(SOC_at_equilibrium - 0.6) < thresh: \n",
    "        terminal = True \n",
    "        reward_factor = reward_factor_temp \n",
    "    else: \n",
    "        terminal = False \n",
    "        reward_factor = reward_factor_temp + 5 * (0.6 - SOC_at_equilibrium)\n",
    "    return reward_factor, terminal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reward factor = 2\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 10.998\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -1157.600774043968 SOC: 0.9993 Cumulative_SOC_deviation: 483.5535 Fuel Consumption: 190.4938 Total Degradation: 524.7037\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 10.533\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -1156.2974056565624 SOC: 1.0000 Cumulative_SOC_deviation: 482.8142 Fuel Consumption: 190.6690 Total Degradation: 525.1414\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 10.115\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -1158.1458442705218 SOC: 0.9999 Cumulative_SOC_deviation: 482.4912 Fuel Consumption: 193.1635 Total Degradation: 523.8406\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 31.369\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -1156.2442633349406 SOC: 0.9997 Cumulative_SOC_deviation: 481.6486 Fuel Consumption: 192.9471 Total Degradation: 523.8828\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.656\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -1154.0896402710398 SOC: 1.0000 Cumulative_SOC_deviation: 481.3856 Fuel Consumption: 191.3184 Total Degradation: 528.9684\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.635\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -1136.9607222580507 SOC: 0.9988 Cumulative_SOC_deviation: 476.8258 Fuel Consumption: 183.3091 Total Degradation: 521.5413\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.809\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -1116.5596998258977 SOC: 1.0000 Cumulative_SOC_deviation: 468.8157 Fuel Consumption: 178.9283 Total Degradation: 522.4457\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.517\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -1080.7780034161926 SOC: 0.9994 Cumulative_SOC_deviation: 453.5070 Fuel Consumption: 173.7640 Total Degradation: 512.9249\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.711\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -1121.3772940843082 SOC: 0.9999 Cumulative_SOC_deviation: 474.6828 Fuel Consumption: 172.0117 Total Degradation: 513.3582\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.320\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -1089.427250770235 SOC: 0.9988 Cumulative_SOC_deviation: 457.8007 Fuel Consumption: 173.8259 Total Degradation: 510.5274\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.277\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -1087.6336069006884 SOC: 1.0000 Cumulative_SOC_deviation: 458.6923 Fuel Consumption: 170.2490 Total Degradation: 505.1230\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.340\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -1071.3118093971032 SOC: 1.0000 Cumulative_SOC_deviation: 452.9435 Fuel Consumption: 165.4249 Total Degradation: 507.6780\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.702\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -1037.3812131747045 SOC: 0.9999 Cumulative_SOC_deviation: 436.0349 Fuel Consumption: 165.3115 Total Degradation: 496.0335\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.919\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -1007.0974336860476 SOC: 1.0000 Cumulative_SOC_deviation: 421.3414 Fuel Consumption: 164.4147 Total Degradation: 497.3142\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.992\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -953.9109152575002 SOC: 0.9993 Cumulative_SOC_deviation: 396.6448 Fuel Consumption: 160.6214 Total Degradation: 485.7109\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.442\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -989.5905006199388 SOC: 0.9974 Cumulative_SOC_deviation: 414.9020 Fuel Consumption: 159.7865 Total Degradation: 486.2088\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.935\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -956.1831176284326 SOC: 0.9978 Cumulative_SOC_deviation: 398.4663 Fuel Consumption: 159.2505 Total Degradation: 487.8279\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.249\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -903.7788817155573 SOC: 1.0000 Cumulative_SOC_deviation: 374.2021 Fuel Consumption: 155.3747 Total Degradation: 467.9251\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.815\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -795.9401282259743 SOC: 0.9999 Cumulative_SOC_deviation: 320.6899 Fuel Consumption: 154.5603 Total Degradation: 460.4179\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.776\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -885.8323433574834 SOC: 1.0000 Cumulative_SOC_deviation: 365.4195 Fuel Consumption: 154.9933 Total Degradation: 464.1962\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.908\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -761.9624392619388 SOC: 0.9975 Cumulative_SOC_deviation: 304.0257 Fuel Consumption: 153.9109 Total Degradation: 466.7439\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.353\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -809.5813357694813 SOC: 0.9925 Cumulative_SOC_deviation: 328.2578 Fuel Consumption: 153.0657 Total Degradation: 447.1558\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.984\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -601.7166355721893 SOC: 0.9627 Cumulative_SOC_deviation: 225.0316 Fuel Consumption: 151.6535 Total Degradation: 433.8532\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.123\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -528.2552574002185 SOC: 0.9305 Cumulative_SOC_deviation: 188.9606 Fuel Consumption: 150.3341 Total Degradation: 431.4440\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.889\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -680.6036671204171 SOC: 0.9583 Cumulative_SOC_deviation: 264.2689 Fuel Consumption: 152.0658 Total Degradation: 430.9642\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.973\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -468.91937374399345 SOC: 0.8779 Cumulative_SOC_deviation: 161.3285 Fuel Consumption: 146.2625 Total Degradation: 419.2967\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.982\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -474.4737742615233 SOC: 0.9175 Cumulative_SOC_deviation: 162.4048 Fuel Consumption: 149.6641 Total Degradation: 408.4859\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.299\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -342.915906606304 SOC: 0.8040 Cumulative_SOC_deviation: 100.9295 Fuel Consumption: 141.0570 Total Degradation: 395.9811\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.834\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -378.09987971357845 SOC: 0.8403 Cumulative_SOC_deviation: 116.9856 Fuel Consumption: 144.1287 Total Degradation: 402.6630\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.002\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -298.67380448861525 SOC: 0.7942 Cumulative_SOC_deviation: 78.8033 Fuel Consumption: 141.0673 Total Degradation: 397.2582\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.644\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -325.66866282942027 SOC: 0.6596 Cumulative_SOC_deviation: 97.1609 Fuel Consumption: 131.3469 Total Degradation: 381.8675\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.686\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -282.12740002317724 SOC: 0.7055 Cumulative_SOC_deviation: 73.9471 Fuel Consumption: 134.2331 Total Degradation: 375.1547\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.292\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -518.7344319592872 SOC: 0.4573 Cumulative_SOC_deviation: 201.5948 Fuel Consumption: 115.5449 Total Degradation: 360.2286\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.182\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -499.94140389583725 SOC: 0.4889 Cumulative_SOC_deviation: 191.0644 Fuel Consumption: 117.8126 Total Degradation: 361.9026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.490\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -409.42083881596517 SOC: 0.5126 Cumulative_SOC_deviation: 144.9022 Fuel Consumption: 119.6165 Total Degradation: 358.9759\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.164\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -530.3293361496494 SOC: 0.4246 Cumulative_SOC_deviation: 208.5828 Fuel Consumption: 113.1637 Total Degradation: 338.1299\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.636\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -578.6125853317424 SOC: 0.3407 Cumulative_SOC_deviation: 236.2910 Fuel Consumption: 106.0306 Total Degradation: 346.0763\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.508\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -628.3446371677803 SOC: 0.3303 Cumulative_SOC_deviation: 260.7601 Fuel Consumption: 106.8244 Total Degradation: 341.4835\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.051\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -607.9620207639516 SOC: 0.3991 Cumulative_SOC_deviation: 248.0073 Fuel Consumption: 111.9474 Total Degradation: 342.2981\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.104\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -637.2907986073371 SOC: 0.3167 Cumulative_SOC_deviation: 265.7641 Fuel Consumption: 105.7626 Total Degradation: 329.4157\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.819\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -799.3621869959187 SOC: 0.2389 Cumulative_SOC_deviation: 349.2531 Fuel Consumption: 100.8561 Total Degradation: 315.1991\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:270: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.703\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -962.0182043415175 SOC: 0.0561 Cumulative_SOC_deviation: 437.0029 Fuel Consumption: 88.0124 Total Degradation: 311.4972\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.585\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -837.7240279507813 SOC: 0.1551 Cumulative_SOC_deviation: 371.3820 Fuel Consumption: 94.9599 Total Degradation: 308.1443\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.199\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -954.7731203787026 SOC: 0.0820 Cumulative_SOC_deviation: 432.0197 Fuel Consumption: 90.7337 Total Degradation: 291.4597\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.151\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -950.0602825102762 SOC: 0.0477 Cumulative_SOC_deviation: 431.1734 Fuel Consumption: 87.7135 Total Degradation: 283.9728\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.201\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -887.068722565005 SOC: 0.1003 Cumulative_SOC_deviation: 398.1005 Fuel Consumption: 90.8677 Total Degradation: 306.9301\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.684\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -910.5091678795382 SOC: 0.0802 Cumulative_SOC_deviation: 410.2176 Fuel Consumption: 90.0740 Total Degradation: 298.9906\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.753\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -1073.11296391837 SOC: 0.0296 Cumulative_SOC_deviation: 493.2306 Fuel Consumption: 86.6517 Total Degradation: 286.8947\n",
      "\n",
      "battery power is 5445.9304832908065(+) but condition is not avail\n",
      "elapsed_time: 79.175\n",
      "Episode: 49 Exploration P: 0.2958 Total reward: [-1916.72401565] SOC: -0.0009 Cumulative_SOC_deviation: 421.8738 Fuel Consumption: 74.1792 Total Degradation: 242.3199\n",
      "\n",
      "battery power is 3842.0652745216203(+) but condition is not avail\n",
      "elapsed_time: 71.469\n",
      "Episode: 50 Exploration P: 0.2891 Total reward: [-1839.42038101] SOC: -0.0000 Cumulative_SOC_deviation: 384.9926 Fuel Consumption: 70.6360 Total Degradation: 227.1865\n",
      "\n",
      "battery power is 8881.337953209346(+) but condition is not avail\n",
      "elapsed_time: 52.656\n",
      "Episode: 51 Exploration P: 0.2836 Total reward: [-1744.92786311] SOC: -0.0001 Cumulative_SOC_deviation: 344.2466 Fuel Consumption: 57.6358 Total Degradation: 200.5199\n",
      "\n",
      "battery power is 6468.585596721082(+) but condition is not avail\n",
      "elapsed_time: 52.032\n",
      "Episode: 52 Exploration P: 0.2785 Total reward: [-1712.24440406] SOC: -0.0001 Cumulative_SOC_deviation: 330.2985 Fuel Consumption: 52.8484 Total Degradation: 166.5327\n",
      "\n",
      "battery power is 6932.917864542715(+) but condition is not avail\n",
      "elapsed_time: 68.968\n",
      "Episode: 53 Exploration P: 0.2717 Total reward: [-1988.97491887] SOC: -0.0011 Cumulative_SOC_deviation: 455.8097 Fuel Consumption: 78.5586 Total Degradation: 246.6200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:271: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery power is 6289.483109771652(+) but condition is not avail\n",
      "elapsed_time: 49.053\n",
      "Episode: 54 Exploration P: 0.2670 Total reward: [-1680.55414952] SOC: -0.0001 Cumulative_SOC_deviation: 315.5427 Fuel Consumption: 50.6699 Total Degradation: 172.3316\n",
      "\n",
      "battery power is 9421.963790156098(+) but condition is not avail\n",
      "elapsed_time: 53.002\n",
      "Episode: 55 Exploration P: 0.2619 Total reward: [-1744.60165881] SOC: -0.0005 Cumulative_SOC_deviation: 344.4309 Fuel Consumption: 56.9418 Total Degradation: 180.4563\n",
      "\n",
      "battery power is 8687.290173603826(+) but condition is not avail\n",
      "elapsed_time: 49.334\n",
      "Episode: 56 Exploration P: 0.2574 Total reward: [-1614.6826966] SOC: -0.0008 Cumulative_SOC_deviation: 283.8857 Fuel Consumption: 48.1138 Total Degradation: 162.2872\n",
      "\n",
      "battery power is 2701.524265944465(+) but condition is not avail\n",
      "elapsed_time: 47.197\n",
      "Episode: 57 Exploration P: 0.2531 Total reward: [-1610.13412834] SOC: -0.0004 Cumulative_SOC_deviation: 282.5737 Fuel Consumption: 46.2812 Total Degradation: 153.4674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.681\n",
      "Episode: 58 Exploration P: 0.2465 Total reward: -602.3414025980147 SOC: 0.5524 Cumulative_SOC_deviation: 240.0516 Fuel Consumption: 122.2383 Total Degradation: 408.0717\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.940\n",
      "Episode: 59 Exploration P: 0.2401 Total reward: -314.986813032441 SOC: 0.4857 Cumulative_SOC_deviation: 101.9059 Fuel Consumption: 111.1750 Total Degradation: 470.8545\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.384\n",
      "Episode: 60 Exploration P: 0.2339 Total reward: -298.52947157822996 SOC: 0.4355 Cumulative_SOC_deviation: 94.2238 Fuel Consumption: 110.0819 Total Degradation: 409.3844\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.889\n",
      "Episode: 61 Exploration P: 0.2278 Total reward: -802.7166423664287 SOC: 0.3110 Cumulative_SOC_deviation: 348.6476 Fuel Consumption: 105.4215 Total Degradation: 340.2872\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.852\n",
      "Episode: 62 Exploration P: 0.2219 Total reward: -724.9501655272479 SOC: 0.3171 Cumulative_SOC_deviation: 309.8968 Fuel Consumption: 105.1566 Total Degradation: 332.8716\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.764\n",
      "Episode: 63 Exploration P: 0.2162 Total reward: -781.0985695950529 SOC: 0.2036 Cumulative_SOC_deviation: 342.1384 Fuel Consumption: 96.8218 Total Degradation: 290.4174\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.226\n",
      "Episode: 64 Exploration P: 0.2106 Total reward: -840.0145387814106 SOC: 0.4981 Cumulative_SOC_deviation: 358.4825 Fuel Consumption: 123.0495 Total Degradation: 347.3340\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.587\n",
      "Episode: 65 Exploration P: 0.2052 Total reward: -449.9496179070723 SOC: 0.5350 Cumulative_SOC_deviation: 160.9711 Fuel Consumption: 128.0075 Total Degradation: 321.1345\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.024\n",
      "Episode: 66 Exploration P: 0.1999 Total reward: -842.060445420124 SOC: 0.3805 Cumulative_SOC_deviation: 361.8399 Fuel Consumption: 118.3807 Total Degradation: 283.2555\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.138\n",
      "Episode: 67 Exploration P: 0.1947 Total reward: -279.2606107183278 SOC: 0.5043 Cumulative_SOC_deviation: 79.0607 Fuel Consumption: 121.1393 Total Degradation: 326.9389\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.409\n",
      "Episode: 68 Exploration P: 0.1897 Total reward: -414.68652355849207 SOC: 0.4835 Cumulative_SOC_deviation: 145.8353 Fuel Consumption: 123.0159 Total Degradation: 325.2546\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.335\n",
      "Episode: 69 Exploration P: 0.1849 Total reward: -662.8110175920606 SOC: 0.2737 Cumulative_SOC_deviation: 279.9839 Fuel Consumption: 102.8431 Total Degradation: 325.3271\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.469\n",
      "Episode: 70 Exploration P: 0.1801 Total reward: -515.2954626915529 SOC: 0.5464 Cumulative_SOC_deviation: 194.5421 Fuel Consumption: 126.2113 Total Degradation: 316.5414\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.830\n",
      "Episode: 71 Exploration P: 0.1755 Total reward: -863.0147702724039 SOC: 0.3111 Cumulative_SOC_deviation: 376.1744 Fuel Consumption: 110.6660 Total Degradation: 320.3629\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.114\n",
      "Episode: 72 Exploration P: 0.1710 Total reward: -330.5046377251922 SOC: 0.3585 Cumulative_SOC_deviation: 111.7029 Fuel Consumption: 107.0988 Total Degradation: 330.3404\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.830\n",
      "Episode: 73 Exploration P: 0.1667 Total reward: -474.5415609531954 SOC: 0.5453 Cumulative_SOC_deviation: 174.6531 Fuel Consumption: 125.2354 Total Degradation: 304.1304\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.660\n",
      "Episode: 74 Exploration P: 0.1624 Total reward: -307.5347425727673 SOC: 0.5442 Cumulative_SOC_deviation: 92.4417 Fuel Consumption: 122.6513 Total Degradation: 355.7088\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.593\n",
      "Episode: 75 Exploration P: 0.1583 Total reward: -418.64818225860984 SOC: 0.3039 Cumulative_SOC_deviation: 158.1915 Fuel Consumption: 102.2652 Total Degradation: 332.8405\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.514\n",
      "Episode: 76 Exploration P: 0.1543 Total reward: -657.8241514217556 SOC: 0.5127 Cumulative_SOC_deviation: 265.2810 Fuel Consumption: 127.2622 Total Degradation: 299.0627\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.643\n",
      "Episode: 77 Exploration P: 0.1504 Total reward: -545.4384354631673 SOC: 0.5317 Cumulative_SOC_deviation: 208.2936 Fuel Consumption: 128.8511 Total Degradation: 275.2511\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.263\n",
      "Episode: 78 Exploration P: 0.1466 Total reward: -566.2773137558879 SOC: 0.5788 Cumulative_SOC_deviation: 215.6350 Fuel Consumption: 135.0072 Total Degradation: 246.9062\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.579\n",
      "Episode: 79 Exploration P: 0.1429 Total reward: -673.5974921932113 SOC: 0.1699 Cumulative_SOC_deviation: 287.3969 Fuel Consumption: 98.8037 Total Degradation: 266.2198\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.274\n",
      "Episode: 80 Exploration P: 0.1393 Total reward: -1178.065833672943 SOC: 0.2149 Cumulative_SOC_deviation: 536.4652 Fuel Consumption: 105.1354 Total Degradation: 292.4096\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.684\n",
      "Episode: 81 Exploration P: 0.1358 Total reward: -972.8774344936952 SOC: 0.1696 Cumulative_SOC_deviation: 436.1477 Fuel Consumption: 100.5820 Total Degradation: 297.8645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.488\n",
      "Episode: 82 Exploration P: 0.1324 Total reward: -1299.5357205868524 SOC: 0.1073 Cumulative_SOC_deviation: 602.4483 Fuel Consumption: 94.6392 Total Degradation: 299.0049\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.134\n",
      "Episode: 83 Exploration P: 0.1290 Total reward: -1170.6141599850587 SOC: 0.1568 Cumulative_SOC_deviation: 536.9429 Fuel Consumption: 96.7284 Total Degradation: 313.1854\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.363\n",
      "Episode: 84 Exploration P: 0.1258 Total reward: -1271.978565004898 SOC: 0.1669 Cumulative_SOC_deviation: 586.9567 Fuel Consumption: 98.0651 Total Degradation: 304.8299\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.940\n",
      "Episode: 85 Exploration P: 0.1227 Total reward: -1226.4548588000318 SOC: 0.0977 Cumulative_SOC_deviation: 566.0533 Fuel Consumption: 94.3482 Total Degradation: 278.6857\n",
      "\n",
      "battery power is 12944.456243848224(+) but condition is not avail\n",
      "elapsed_time: 56.797\n",
      "Episode: 86 Exploration P: 0.1207 Total reward: [-1776.02543031] SOC: -0.0010 Cumulative_SOC_deviation: 365.1950 Fuel Consumption: 46.8382 Total Degradation: 140.8118\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.324\n",
      "Episode: 87 Exploration P: 0.1177 Total reward: -1240.8510306388694 SOC: 0.0916 Cumulative_SOC_deviation: 574.7545 Fuel Consumption: 91.3421 Total Degradation: 273.6685\n",
      "\n",
      "battery power is 3277.608098314371(+) but condition is not avail\n",
      "elapsed_time: 50.208\n",
      "Episode: 88 Exploration P: 0.1161 Total reward: [-1611.74181631] SOC: -0.0001 Cumulative_SOC_deviation: 288.1576 Fuel Consumption: 36.6277 Total Degradation: 88.1144\n",
      "\n",
      "battery power is 9491.754015579985(+) but condition is not avail\n",
      "elapsed_time: 31.365\n",
      "Episode: 89 Exploration P: 0.1151 Total reward: [-1310.51908563] SOC: -0.0001 Cumulative_SOC_deviation: 148.9211 Fuel Consumption: 13.8778 Total Degradation: 44.0583\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery power is 12112.741162676295(+) but condition is not avail\n",
      "elapsed_time: 33.982\n",
      "Episode: 90 Exploration P: 0.1140 Total reward: [-1350.34450923] SOC: -0.0004 Cumulative_SOC_deviation: 167.6712 Fuel Consumption: 16.2036 Total Degradation: 50.0015\n",
      "\n",
      "battery power is 1734.955034069886(+) but condition is not avail\n",
      "elapsed_time: 35.055\n",
      "Episode: 91 Exploration P: 0.1128 Total reward: [-1377.37456745] SOC: -0.0005 Cumulative_SOC_deviation: 180.2162 Fuel Consumption: 18.1439 Total Degradation: 56.3055\n",
      "\n",
      "battery power is 11066.014603911986(+) but condition is not avail\n",
      "elapsed_time: 36.819\n",
      "Episode: 92 Exploration P: 0.1117 Total reward: [-1377.04939705] SOC: -0.0000 Cumulative_SOC_deviation: 179.2692 Fuel Consumption: 19.7118 Total Degradation: 66.3976\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.820\n",
      "Episode: 93 Exploration P: 0.1089 Total reward: -1164.5728638062892 SOC: 0.1471 Cumulative_SOC_deviation: 533.1656 Fuel Consumption: 98.2417 Total Degradation: 255.7632\n",
      "\n",
      "battery power is 3952.2688942749637(+) but condition is not avail\n",
      "elapsed_time: 88.599\n",
      "Episode: 94 Exploration P: 0.1063 Total reward: [-2144.71198277] SOC: -0.0002 Cumulative_SOC_deviation: 529.3902 Fuel Consumption: 87.1328 Total Degradation: 260.7119\n",
      "\n",
      "battery power is 166.48717685563042(+) but condition is not avail\n",
      "elapsed_time: 38.618\n",
      "Episode: 95 Exploration P: 0.1051 Total reward: [-1426.84188133] SOC: -0.0008 Cumulative_SOC_deviation: 203.2393 Fuel Consumption: 21.6584 Total Degradation: 71.8405\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.914\n",
      "Episode: 96 Exploration P: 0.1025 Total reward: -1261.3439266819307 SOC: 0.0555 Cumulative_SOC_deviation: 585.6199 Fuel Consumption: 90.1041 Total Degradation: 311.4950\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.395\n",
      "Episode: 97 Exploration P: 0.1000 Total reward: -1265.1961797506458 SOC: 0.1434 Cumulative_SOC_deviation: 584.2230 Fuel Consumption: 96.7501 Total Degradation: 286.0527\n",
      "\n",
      "battery power is 6632.515505996046(+) but condition is not avail\n",
      "elapsed_time: 34.841\n",
      "Episode: 98 Exploration P: 0.0991 Total reward: [-1374.70972933] SOC: -0.0001 Cumulative_SOC_deviation: 177.3770 Fuel Consumption: 21.1927 Total Degradation: 56.2737\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.067\n",
      "Episode: 99 Exploration P: 0.0967 Total reward: -1242.8442188170688 SOC: 0.1124 Cumulative_SOC_deviation: 573.9495 Fuel Consumption: 94.9452 Total Degradation: 251.5169\n",
      "\n",
      "battery power is 6917.947450410809(+) but condition is not avail\n",
      "elapsed_time: 29.083\n",
      "Episode: 100 Exploration P: 0.0957 Total reward: [-1373.30575084] SOC: -0.0006 Cumulative_SOC_deviation: 178.1573 Fuel Consumption: 18.1956 Total Degradation: 55.4613\n",
      "\n",
      "battery power is 7590.055419832917(+) but condition is not avail\n",
      "elapsed_time: 30.894\n",
      "Episode: 101 Exploration P: 0.0947 Total reward: [-1406.0177774] SOC: -0.0010 Cumulative_SOC_deviation: 193.4401 Fuel Consumption: 20.3420 Total Degradation: 56.3849\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.087\n",
      "Episode: 102 Exploration P: 0.0924 Total reward: -1406.5774057643266 SOC: 0.0291 Cumulative_SOC_deviation: 659.5196 Fuel Consumption: 87.5382 Total Degradation: 275.1837\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.496\n",
      "Episode: 103 Exploration P: 0.0902 Total reward: -1196.3182678748328 SOC: 0.1151 Cumulative_SOC_deviation: 551.6722 Fuel Consumption: 92.9738 Total Degradation: 234.7962\n",
      "\n",
      "battery power is 11453.938250449675(+) but condition is not avail\n",
      "elapsed_time: 71.875\n",
      "Episode: 104 Exploration P: 0.0881 Total reward: [-2268.91893358] SOC: -0.0002 Cumulative_SOC_deviation: 592.8270 Fuel Consumption: 84.4853 Total Degradation: 344.2146\n",
      "\n",
      "battery power is 15192.296270341789(+) but condition is not avail\n",
      "elapsed_time: 32.561\n",
      "Episode: 105 Exploration P: 0.0871 Total reward: [-1489.3946247] SOC: -0.0017 Cumulative_SOC_deviation: 222.3431 Fuel Consumption: 45.9128 Total Degradation: 86.0653\n",
      "\n",
      "battery power is 156.85603872318825(+) but condition is not avail\n",
      "elapsed_time: 26.065\n",
      "Episode: 106 Exploration P: 0.0864 Total reward: [-1321.65563344] SOC: -0.0015 Cumulative_SOC_deviation: 153.6288 Fuel Consumption: 15.6946 Total Degradation: 45.7142\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.389\n",
      "Episode: 107 Exploration P: 0.0843 Total reward: -1332.4659791772572 SOC: 0.0516 Cumulative_SOC_deviation: 622.6096 Fuel Consumption: 87.2467 Total Degradation: 327.1762\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.727\n",
      "Episode: 108 Exploration P: 0.0823 Total reward: -1218.7568274384182 SOC: 0.1132 Cumulative_SOC_deviation: 564.0683 Fuel Consumption: 90.6203 Total Degradation: 361.7457\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.334\n",
      "Episode: 109 Exploration P: 0.0804 Total reward: -1351.3108638704427 SOC: 0.0225 Cumulative_SOC_deviation: 631.0635 Fuel Consumption: 89.1838 Total Degradation: 332.6504\n",
      "\n",
      "battery power is 16646.12051413104(+) but condition is not avail\n",
      "elapsed_time: 67.291\n",
      "Episode: 110 Exploration P: 0.0786 Total reward: [-2279.95714428] SOC: -0.0000 Cumulative_SOC_deviation: 597.4462 Fuel Consumption: 86.2734 Total Degradation: 270.0026\n",
      "\n",
      "battery power is 7912.778423070128(+) but condition is not avail\n",
      "elapsed_time: 27.911\n",
      "Episode: 111 Exploration P: 0.0779 Total reward: [-1375.84548476] SOC: -0.0001 Cumulative_SOC_deviation: 172.1289 Fuel Consumption: 32.8531 Total Degradation: 44.5748\n",
      "\n",
      "battery power is 12656.134720519012(+) but condition is not avail\n",
      "elapsed_time: 27.916\n",
      "Episode: 112 Exploration P: 0.0772 Total reward: [-1375.86702883] SOC: -0.0009 Cumulative_SOC_deviation: 174.1597 Fuel Consumption: 28.7602 Total Degradation: 44.9958\n",
      "\n",
      "battery power is 16509.353452352945(+) but condition is not avail\n",
      "elapsed_time: 51.552\n",
      "Episode: 113 Exploration P: 0.0759 Total reward: [-1927.52860722] SOC: -0.0002 Cumulative_SOC_deviation: 424.9694 Fuel Consumption: 78.7910 Total Degradation: 216.3532\n",
      "\n",
      "battery power is 431.7609760916239(+) but condition is not avail\n",
      "elapsed_time: 30.532\n",
      "Episode: 114 Exploration P: 0.0751 Total reward: [-1433.2922181] SOC: -0.0006 Cumulative_SOC_deviation: 194.9842 Fuel Consumption: 44.6338 Total Degradation: 64.2713\n",
      "\n",
      "battery power is 12302.191151948049(+) but condition is not avail\n",
      "elapsed_time: 30.567\n",
      "Episode: 115 Exploration P: 0.0744 Total reward: [-1445.09778663] SOC: -0.0001 Cumulative_SOC_deviation: 198.3534 Fuel Consumption: 49.6097 Total Degradation: 63.4802\n",
      "\n",
      "battery power is 11204.567840137763(+) but condition is not avail\n",
      "elapsed_time: 59.281\n",
      "Episode: 116 Exploration P: 0.0730 Total reward: [-2111.27722049] SOC: -0.0005 Cumulative_SOC_deviation: 503.1700 Fuel Consumption: 106.1392 Total Degradation: 195.5059\n",
      "\n",
      "battery power is 8912.454629108703(+) but condition is not avail\n",
      "elapsed_time: 28.383\n",
      "Episode: 117 Exploration P: 0.0723 Total reward: [-1402.13639301] SOC: -0.0009 Cumulative_SOC_deviation: 178.3944 Fuel Consumption: 46.5502 Total Degradation: 55.9063\n",
      "\n",
      "battery power is 7264.419125476739(+) but condition is not avail\n",
      "elapsed_time: 64.757\n",
      "Episode: 118 Exploration P: 0.0709 Total reward: [-2057.87802037] SOC: -0.0008 Cumulative_SOC_deviation: 482.0522 Fuel Consumption: 94.9760 Total Degradation: 144.5697\n",
      "\n",
      "battery power is 6526.981902015126(+) but condition is not avail\n",
      "elapsed_time: 31.232\n",
      "Episode: 119 Exploration P: 0.0702 Total reward: [-1430.04150893] SOC: -0.0005 Cumulative_SOC_deviation: 198.9527 Fuel Consumption: 33.3379 Total Degradation: 56.0120\n",
      "\n",
      "battery power is 17416.980131955585(+) but condition is not avail\n",
      "elapsed_time: 39.696\n",
      "Episode: 120 Exploration P: 0.0693 Total reward: [-1701.10824725] SOC: -0.0000 Cumulative_SOC_deviation: 289.7667 Fuel Consumption: 122.7756 Total Degradation: 94.4734\n",
      "\n",
      "battery power is 9354.364313244268(+) but condition is not avail\n",
      "elapsed_time: 32.260\n",
      "Episode: 121 Exploration P: 0.0686 Total reward: [-1498.58544801] SOC: -0.0007 Cumulative_SOC_deviation: 219.7389 Fuel Consumption: 60.3100 Total Degradation: 59.0139\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.098\n",
      "Episode: 122 Exploration P: 0.0670 Total reward: -1238.584182164051 SOC: 0.1128 Cumulative_SOC_deviation: 571.3761 Fuel Consumption: 95.8320 Total Degradation: 189.9224\n",
      "\n",
      "battery power is 7171.136232162809(+) but condition is not avail\n",
      "elapsed_time: 49.892\n",
      "Episode: 123 Exploration P: 0.0659 Total reward: [-1858.59283] SOC: -0.0003 Cumulative_SOC_deviation: 388.8837 Fuel Consumption: 82.0269 Total Degradation: 123.5171\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery power is 4855.669210900852(+) but condition is not avail\n",
      "elapsed_time: 56.784\n",
      "Episode: 124 Exploration P: 0.0647 Total reward: [-2021.34552331] SOC: -0.0005 Cumulative_SOC_deviation: 478.3386 Fuel Consumption: 65.9628 Total Degradation: 219.1068\n",
      "\n",
      "battery power is 4771.432547073186(+) but condition is not avail\n",
      "elapsed_time: 42.280\n",
      "Episode: 125 Exploration P: 0.0639 Total reward: [-1930.7997392] SOC: -0.0007 Cumulative_SOC_deviation: 334.2135 Fuel Consumption: 263.5750 Total Degradation: 75.8468\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.363\n",
      "Episode: 126 Exploration P: 0.0624 Total reward: -1376.2760415860728 SOC: -0.0006 Cumulative_SOC_deviation: 615.5669 Fuel Consumption: 145.1422 Total Degradation: 172.9086\n",
      "\n",
      "battery power is 8348.344284713574(+) but condition is not avail\n",
      "elapsed_time: 68.567\n",
      "Episode: 127 Exploration P: 0.0611 Total reward: [-2284.89947942] SOC: -0.0003 Cumulative_SOC_deviation: 595.1420 Fuel Consumption: 95.8169 Total Degradation: 152.5816\n",
      "\n",
      "battery power is 6932.917864542715(+) but condition is not avail\n",
      "elapsed_time: 68.698\n",
      "Episode: 128 Exploration P: 0.0598 Total reward: [-2402.78904343] SOC: -0.0000 Cumulative_SOC_deviation: 604.8269 Fuel Consumption: 194.3361 Total Degradation: 169.4237\n",
      "\n",
      "battery power is 4556.04963138524(+) but condition is not avail\n",
      "elapsed_time: 41.073\n",
      "Episode: 129 Exploration P: 0.0590 Total reward: [-1856.35992458] SOC: -0.0006 Cumulative_SOC_deviation: 319.9677 Fuel Consumption: 217.6265 Total Degradation: 66.1658\n",
      "\n",
      "battery power is 4556.04963138524(+) but condition is not avail\n",
      "elapsed_time: 62.275\n",
      "Episode: 130 Exploration P: 0.0579 Total reward: [-2196.96336929] SOC: -0.0005 Cumulative_SOC_deviation: 520.7656 Fuel Consumption: 156.6339 Total Degradation: 169.9116\n",
      "\n",
      "battery power is 4224.368500484229(+) but condition is not avail\n",
      "elapsed_time: 71.806\n",
      "Episode: 131 Exploration P: 0.0566 Total reward: [-2916.24580543] SOC: -0.0000 Cumulative_SOC_deviation: 666.2718 Fuel Consumption: 584.9960 Total Degradation: 116.8984\n",
      "\n",
      "battery power is 5204.826318047967(+) but condition is not avail\n",
      "elapsed_time: 34.951\n",
      "Episode: 132 Exploration P: 0.0560 Total reward: [-1610.93739215] SOC: -0.0010 Cumulative_SOC_deviation: 252.8710 Fuel Consumption: 106.4909 Total Degradation: 61.6488\n",
      "\n",
      "battery power is 9989.026573625564(+) but condition is not avail\n",
      "elapsed_time: 37.959\n",
      "Episode: 133 Exploration P: 0.0554 Total reward: [-1685.6696173] SOC: -0.0009 Cumulative_SOC_deviation: 277.2964 Fuel Consumption: 132.2795 Total Degradation: 65.1206\n",
      "\n",
      "battery power is 8274.871761553288(+) but condition is not avail\n",
      "elapsed_time: 52.365\n",
      "Episode: 134 Exploration P: 0.0545 Total reward: [-1993.17594781] SOC: -0.0001 Cumulative_SOC_deviation: 431.2924 Fuel Consumption: 131.7922 Total Degradation: 96.5431\n",
      "\n",
      "battery power is 14392.703454436605(+) but condition is not avail\n",
      "elapsed_time: 35.128\n",
      "Episode: 135 Exploration P: 0.0539 Total reward: [-1514.60273851] SOC: -0.0005 Cumulative_SOC_deviation: 239.6078 Fuel Consumption: 36.5889 Total Degradation: 55.3567\n",
      "\n",
      "battery power is 14043.54634728949(+) but condition is not avail\n",
      "elapsed_time: 56.823\n",
      "Episode: 136 Exploration P: 0.0530 Total reward: [-1945.24818585] SOC: -0.0006 Cumulative_SOC_deviation: 437.2191 Fuel Consumption: 72.0120 Total Degradation: 125.8685\n",
      "\n",
      "battery power is 2881.7069956106006(+) but condition is not avail\n",
      "elapsed_time: 57.193\n",
      "Episode: 137 Exploration P: 0.0521 Total reward: [-2364.58156957] SOC: -0.0002 Cumulative_SOC_deviation: 492.5909 Fuel Consumption: 380.6939 Total Degradation: 113.3535\n",
      "\n",
      "battery power is 274.26399360194955(+) but condition is not avail\n",
      "elapsed_time: 29.404\n",
      "Episode: 138 Exploration P: 0.0516 Total reward: [-1394.65507424] SOC: -0.0003 Cumulative_SOC_deviation: 188.6573 Fuel Consumption: 18.5436 Total Degradation: 41.7272\n",
      "\n",
      "battery power is 4556.04963138524(+) but condition is not avail\n",
      "elapsed_time: 64.122\n",
      "Episode: 139 Exploration P: 0.0507 Total reward: [-2420.61984774] SOC: -0.0008 Cumulative_SOC_deviation: 560.1016 Fuel Consumption: 301.6191 Total Degradation: 172.8656\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.913\n",
      "Episode: 140 Exploration P: 0.0496 Total reward: -1748.4694301997 SOC: -0.0002 Cumulative_SOC_deviation: 649.1303 Fuel Consumption: 450.2088 Total Degradation: 121.1151\n",
      "\n",
      "battery power is 5011.529613554158(+) but condition is not avail\n",
      "elapsed_time: 28.800\n",
      "Episode: 141 Exploration P: 0.0491 Total reward: [-1395.62651697] SOC: -0.0007 Cumulative_SOC_deviation: 188.1522 Fuel Consumption: 20.5243 Total Degradation: 40.8549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.495\n",
      "Episode: 142 Exploration P: 0.0481 Total reward: -1335.3211801286322 SOC: 0.0157 Cumulative_SOC_deviation: 623.2425 Fuel Consumption: 88.8362 Total Degradation: 161.5335\n",
      "\n",
      "battery power is 14992.792337348157(+) but condition is not avail\n",
      "elapsed_time: 41.632\n",
      "Episode: 143 Exploration P: 0.0475 Total reward: [-1864.49558852] SOC: -0.0013 Cumulative_SOC_deviation: 326.0219 Fuel Consumption: 213.6936 Total Degradation: 85.4383\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.409\n",
      "Episode: 144 Exploration P: 0.0465 Total reward: -1317.6868696089027 SOC: 0.0465 Cumulative_SOC_deviation: 613.2245 Fuel Consumption: 91.2379 Total Degradation: 176.1728\n",
      "\n",
      "battery power is 5962.646327994909(+) but condition is not avail\n",
      "elapsed_time: 43.879\n",
      "Episode: 145 Exploration P: 0.0459 Total reward: [-1873.73295854] SOC: -0.0002 Cumulative_SOC_deviation: 340.1174 Fuel Consumption: 194.6992 Total Degradation: 62.4998\n",
      "\n",
      "battery power is 6650.500626537845(+) but condition is not avail\n",
      "elapsed_time: 50.792\n",
      "Episode: 146 Exploration P: 0.0452 Total reward: [-2129.82157896] SOC: -0.0006 Cumulative_SOC_deviation: 416.9613 Fuel Consumption: 297.1010 Total Degradation: 82.0525\n",
      "\n",
      "battery power is 9089.678575209442(+) but condition is not avail\n",
      "elapsed_time: 40.385\n",
      "Episode: 147 Exploration P: 0.0447 Total reward: [-1789.7086874] SOC: -0.0002 Cumulative_SOC_deviation: 309.0637 Fuel Consumption: 172.7826 Total Degradation: 90.7595\n",
      "\n",
      "battery power is 4064.9898875146855(+) but condition is not avail\n",
      "elapsed_time: 57.396\n",
      "Episode: 148 Exploration P: 0.0439 Total reward: [-2018.27220935] SOC: -0.0006 Cumulative_SOC_deviation: 469.2646 Fuel Consumption: 81.0379 Total Degradation: 138.7422\n",
      "\n",
      "battery power is 9656.244502195941(+) but condition is not avail\n",
      "elapsed_time: 53.977\n",
      "Episode: 149 Exploration P: 0.0433 Total reward: [-2196.14929461] SOC: -0.0003 Cumulative_SOC_deviation: 448.3125 Fuel Consumption: 300.7259 Total Degradation: 80.5160\n",
      "\n",
      "battery power is 9569.911663165443(+) but condition is not avail\n",
      "elapsed_time: 52.587\n",
      "Episode: 150 Exploration P: 0.0426 Total reward: [-1875.4846455] SOC: -0.0001 Cumulative_SOC_deviation: 387.4609 Fuel Consumption: 101.7637 Total Degradation: 105.3023\n",
      "\n",
      "model is saved..\n",
      "\n",
      "reward factor = 4.970944598169254\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 11.358\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -2600.369375734464 SOC: 1.0000 Cumulative_SOC_deviation: 484.1329 Fuel Consumption: 193.7717 Total Degradation: 528.0320\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 11.006\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -2639.4099008050016 SOC: 1.0000 Cumulative_SOC_deviation: 492.9612 Fuel Consumption: 188.9270 Total Degradation: 522.5991\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 11.112\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -2595.351210180586 SOC: 1.0000 Cumulative_SOC_deviation: 483.3805 Fuel Consumption: 192.4935 Total Degradation: 524.2803\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer batch_normalization_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 33.000\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -2573.5675459693734 SOC: 0.9988 Cumulative_SOC_deviation: 480.3171 Fuel Consumption: 185.9377 Total Degradation: 525.5880\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.870\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -2577.1903341202897 SOC: 0.9997 Cumulative_SOC_deviation: 481.1579 Fuel Consumption: 185.3810 Total Degradation: 520.1981\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.400\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -2571.120811760534 SOC: 1.0000 Cumulative_SOC_deviation: 479.9245 Fuel Consumption: 185.4429 Total Degradation: 525.2889\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.184\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -2499.2171882287676 SOC: 1.0000 Cumulative_SOC_deviation: 466.7536 Fuel Consumption: 179.0107 Total Degradation: 517.8683\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.693\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -2414.476202591852 SOC: 1.0000 Cumulative_SOC_deviation: 450.0236 Fuel Consumption: 177.4336 Total Degradation: 517.5147\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.647\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -2451.738345555448 SOC: 1.0000 Cumulative_SOC_deviation: 458.1106 Fuel Consumption: 174.4959 Total Degradation: 521.6705\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.618\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -2388.30318966479 SOC: 0.9999 Cumulative_SOC_deviation: 446.0710 Fuel Consumption: 170.9087 Total Degradation: 515.1065\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.948\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -2334.8094857021483 SOC: 0.9995 Cumulative_SOC_deviation: 436.8774 Fuel Consumption: 163.1159 Total Degradation: 505.6546\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.880\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -2406.9350120493227 SOC: 1.0000 Cumulative_SOC_deviation: 450.6134 Fuel Consumption: 166.9608 Total Degradation: 500.6205\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.802\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -2208.514247919936 SOC: 0.9994 Cumulative_SOC_deviation: 411.6221 Fuel Consumption: 162.3634 Total Degradation: 501.1096\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.668\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -2319.6421443079 SOC: 0.9984 Cumulative_SOC_deviation: 433.9092 Fuel Consumption: 162.7036 Total Degradation: 496.0968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.044\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -2233.781557121381 SOC: 0.9994 Cumulative_SOC_deviation: 417.3625 Fuel Consumption: 159.0958 Total Degradation: 487.7862\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.978\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -1979.0634724447943 SOC: 0.9999 Cumulative_SOC_deviation: 366.1418 Fuel Consumption: 158.9928 Total Degradation: 472.8440\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.525\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -1948.9681200761604 SOC: 0.9985 Cumulative_SOC_deviation: 360.7988 Fuel Consumption: 155.4571 Total Degradation: 487.0791\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.397\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -1699.255950894464 SOC: 0.9941 Cumulative_SOC_deviation: 311.0808 Fuel Consumption: 152.8905 Total Degradation: 467.5311\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.714\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -1843.5631237694504 SOC: 0.9883 Cumulative_SOC_deviation: 340.1669 Fuel Consumption: 152.6122 Total Degradation: 465.4691\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.224\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -1740.8275071224648 SOC: 1.0000 Cumulative_SOC_deviation: 319.1970 Fuel Consumption: 154.1171 Total Degradation: 462.9725\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.262\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -1724.6310364394762 SOC: 0.9895 Cumulative_SOC_deviation: 316.2518 Fuel Consumption: 152.5606 Total Degradation: 458.8096\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.971\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -1457.086596428563 SOC: 0.9842 Cumulative_SOC_deviation: 262.3369 Fuel Consumption: 153.0245 Total Degradation: 446.3488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.574\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1566.1743291181235 SOC: 0.9909 Cumulative_SOC_deviation: 284.2011 Fuel Consumption: 153.4265 Total Degradation: 443.4061\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.634\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1377.0910209065705 SOC: 0.9791 Cumulative_SOC_deviation: 246.1655 Fuel Consumption: 153.4162 Total Degradation: 430.1248\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.592\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1117.177173488149 SOC: 0.9446 Cumulative_SOC_deviation: 194.4138 Fuel Consumption: 150.7567 Total Degradation: 433.5045\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.023\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -853.6134882752286 SOC: 0.9253 Cumulative_SOC_deviation: 141.3391 Fuel Consumption: 151.0247 Total Degradation: 422.6496\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.736\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -425.5470565931129 SOC: 0.7499 Cumulative_SOC_deviation: 58.0372 Fuel Consumption: 137.0472 Total Degradation: 392.7039\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.677\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -647.0863930015394 SOC: 0.7898 Cumulative_SOC_deviation: 101.9592 Fuel Consumption: 140.2530 Total Degradation: 405.6114\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.677\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -637.7283072662565 SOC: 0.8311 Cumulative_SOC_deviation: 99.4338 Fuel Consumption: 143.4484 Total Degradation: 410.6045\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.838\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -422.1075061654562 SOC: 0.6719 Cumulative_SOC_deviation: 58.5003 Fuel Consumption: 131.3057 Total Degradation: 388.1269\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.189\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -472.68620295415724 SOC: 0.6830 Cumulative_SOC_deviation: 68.4823 Fuel Consumption: 132.2643 Total Degradation: 386.4566\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.543\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -336.2079285282539 SOC: 0.7073 Cumulative_SOC_deviation: 40.6186 Fuel Consumption: 134.2950 Total Degradation: 386.4529\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.212\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -713.9817446492348 SOC: 0.5247 Cumulative_SOC_deviation: 119.4435 Fuel Consumption: 120.2350 Total Degradation: 361.8638\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.356\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -987.0750116129627 SOC: 0.4734 Cumulative_SOC_deviation: 175.1569 Fuel Consumption: 116.3798 Total Degradation: 348.1279\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.031\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -1099.6655078131614 SOC: 0.4447 Cumulative_SOC_deviation: 198.1757 Fuel Consumption: 114.5450 Total Degradation: 352.3108\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.828\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1167.2849443830044 SOC: 0.4117 Cumulative_SOC_deviation: 212.1498 Fuel Consumption: 112.6999 Total Degradation: 344.4054\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.126\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -980.603710224195 SOC: 0.4647 Cumulative_SOC_deviation: 173.8654 Fuel Consumption: 116.3283 Total Degradation: 344.4023\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.522\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1604.9425867181308 SOC: 0.3100 Cumulative_SOC_deviation: 301.7275 Fuel Consumption: 105.0720 Total Degradation: 333.9783\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.709\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1570.3010868062443 SOC: 0.2800 Cumulative_SOC_deviation: 295.3932 Fuel Consumption: 101.9178 Total Degradation: 333.1488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.115\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1590.8676815484828 SOC: 0.2728 Cumulative_SOC_deviation: 299.3585 Fuel Consumption: 102.7733 Total Degradation: 325.2283\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.740\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1388.0773793337598 SOC: 0.3012 Cumulative_SOC_deviation: 258.2979 Fuel Consumption: 104.0928 Total Degradation: 314.8167\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.861\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1859.8771299965501 SOC: 0.1710 Cumulative_SOC_deviation: 354.8144 Fuel Consumption: 96.1144 Total Degradation: 315.6533\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.563\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -2515.2085811813295 SOC: 0.0430 Cumulative_SOC_deviation: 488.2538 Fuel Consumption: 88.1258 Total Degradation: 290.6182\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.428\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -2310.908989784704 SOC: 0.1233 Cumulative_SOC_deviation: 445.9939 Fuel Consumption: 93.8982 Total Degradation: 300.2217\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.700\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -2027.4035305845673 SOC: 0.1402 Cumulative_SOC_deviation: 388.8141 Fuel Consumption: 94.6301 Total Degradation: 306.9397\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.219\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -2511.5578143804005 SOC: 0.1176 Cumulative_SOC_deviation: 486.3354 Fuel Consumption: 94.0116 Total Degradation: 303.5745\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.629\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -2460.950192582257 SOC: 0.0385 Cumulative_SOC_deviation: 477.5489 Fuel Consumption: 87.0809 Total Degradation: 315.5550\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.393\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -1665.9793458491777 SOC: 0.3174 Cumulative_SOC_deviation: 314.7304 Fuel Consumption: 101.4721 Total Degradation: 557.2456\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.023\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -189.65502648508607 SOC: 0.5942 Cumulative_SOC_deviation: 14.8430 Fuel Consumption: 115.8713 Total Degradation: 529.8356\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.747\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -1581.3645996472358 SOC: 0.2363 Cumulative_SOC_deviation: 299.2877 Fuel Consumption: 93.6219 Total Degradation: 568.4433\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.491\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -160.8134920813664 SOC: 0.5955 Cumulative_SOC_deviation: 8.8774 Fuel Consumption: 116.6843 Total Degradation: 528.1881\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.639\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -173.1322589363288 SOC: 0.6001 Cumulative_SOC_deviation: 11.3112 Fuel Consumption: 116.9051 Total Degradation: 530.7379\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.565\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -266.08877828996634 SOC: 0.5713 Cumulative_SOC_deviation: 30.4787 Fuel Consumption: 114.5809 Total Degradation: 525.2923\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.127\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -195.93525516418097 SOC: 0.5885 Cumulative_SOC_deviation: 16.3475 Fuel Consumption: 114.6725 Total Degradation: 542.3353\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.087\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -192.84285926803034 SOC: 0.5840 Cumulative_SOC_deviation: 15.7991 Fuel Consumption: 114.3065 Total Degradation: 551.4268\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.785\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -172.98680958000907 SOC: 0.5973 Cumulative_SOC_deviation: 11.5924 Fuel Consumption: 115.3618 Total Degradation: 553.9594\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.217\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -207.95204062583397 SOC: 0.5998 Cumulative_SOC_deviation: 18.5831 Fuel Consumption: 115.5765 Total Degradation: 556.0062\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.907\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -181.22934705619977 SOC: 0.5911 Cumulative_SOC_deviation: 13.5156 Fuel Consumption: 114.0439 Total Degradation: 568.4217\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.801\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -247.26312049211563 SOC: 0.5904 Cumulative_SOC_deviation: 26.7991 Fuel Consumption: 114.0465 Total Degradation: 521.0956\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.394\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -202.41431759367808 SOC: 0.5916 Cumulative_SOC_deviation: 17.8142 Fuel Consumption: 113.8609 Total Degradation: 568.4365\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.079\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -203.4770636295262 SOC: 0.5836 Cumulative_SOC_deviation: 18.3155 Fuel Consumption: 112.4316 Total Degradation: 555.9653\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.098\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -232.08964222422452 SOC: 0.5905 Cumulative_SOC_deviation: 23.6642 Fuel Consumption: 114.4560 Total Degradation: 489.1285\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.221\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -234.94607374819094 SOC: 0.5812 Cumulative_SOC_deviation: 24.6303 Fuel Consumption: 112.5102 Total Degradation: 482.0405\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.618\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -220.73438480723811 SOC: 0.5920 Cumulative_SOC_deviation: 21.4334 Fuel Consumption: 114.1903 Total Degradation: 505.3197\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.820\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -2171.5653266108257 SOC: 0.2993 Cumulative_SOC_deviation: 417.6526 Fuel Consumption: 95.4372 Total Degradation: 563.4526\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.034\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -237.70574369409084 SOC: 0.5837 Cumulative_SOC_deviation: 25.2102 Fuel Consumption: 112.3873 Total Degradation: 517.3672\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.732\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -245.0274892139463 SOC: 0.6038 Cumulative_SOC_deviation: 26.3699 Fuel Consumption: 113.9440 Total Degradation: 533.9632\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.254\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -241.53724717769975 SOC: 0.5759 Cumulative_SOC_deviation: 26.1586 Fuel Consumption: 111.5043 Total Degradation: 544.7524\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.347\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -256.05270052287165 SOC: 0.5750 Cumulative_SOC_deviation: 29.1767 Fuel Consumption: 111.0168 Total Degradation: 554.7339\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.878\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -260.8203827183022 SOC: 0.5782 Cumulative_SOC_deviation: 30.1782 Fuel Consumption: 110.8061 Total Degradation: 572.1424\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.287\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -261.08424034298946 SOC: 0.5783 Cumulative_SOC_deviation: 30.3305 Fuel Consumption: 110.3128 Total Degradation: 556.4227\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.572\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -256.8996975735225 SOC: 0.5616 Cumulative_SOC_deviation: 29.7821 Fuel Consumption: 108.8544 Total Degradation: 570.4853\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.490\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -305.456897371794 SOC: 0.5609 Cumulative_SOC_deviation: 39.6279 Fuel Consumption: 108.4686 Total Degradation: 574.2233\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.442\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -278.1260845175367 SOC: 0.5839 Cumulative_SOC_deviation: 33.6092 Fuel Consumption: 111.0564 Total Degradation: 574.6614\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.264\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -270.54031012853886 SOC: 0.5770 Cumulative_SOC_deviation: 32.5586 Fuel Consumption: 108.6931 Total Degradation: 572.1645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.067\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -259.9210017524104 SOC: 0.5739 Cumulative_SOC_deviation: 30.2769 Fuel Consumption: 109.4161 Total Degradation: 572.9867\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.167\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -252.595335917298 SOC: 0.5714 Cumulative_SOC_deviation: 28.9301 Fuel Consumption: 108.7854 Total Degradation: 558.4550\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.544\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -278.26974679379634 SOC: 0.5790 Cumulative_SOC_deviation: 33.9438 Fuel Consumption: 109.5372 Total Degradation: 570.0860\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.731\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -243.1525880039115 SOC: 0.5755 Cumulative_SOC_deviation: 26.9784 Fuel Consumption: 109.0446 Total Degradation: 558.4550\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.944\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -306.9224757910135 SOC: 0.5727 Cumulative_SOC_deviation: 39.7330 Fuel Consumption: 109.4121 Total Degradation: 560.1094\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.985\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -293.3034974261713 SOC: 0.5851 Cumulative_SOC_deviation: 36.8786 Fuel Consumption: 109.9821 Total Degradation: 565.9155\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.846\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -305.0343244382116 SOC: 0.5681 Cumulative_SOC_deviation: 39.4396 Fuel Consumption: 108.9821 Total Degradation: 573.4027\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.311\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -325.19934094608016 SOC: 0.5740 Cumulative_SOC_deviation: 43.4794 Fuel Consumption: 109.0655 Total Degradation: 567.5826\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.079\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -323.8292639163959 SOC: 0.5638 Cumulative_SOC_deviation: 43.4631 Fuel Consumption: 107.7764 Total Degradation: 572.1352\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.153\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -358.176614982742 SOC: 0.5613 Cumulative_SOC_deviation: 50.2055 Fuel Consumption: 108.6081 Total Degradation: 567.5654\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.765\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -305.47289644721576 SOC: 0.5664 Cumulative_SOC_deviation: 39.7964 Fuel Consumption: 107.6474 Total Degradation: 560.1094\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.743\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -324.4273979027424 SOC: 0.5620 Cumulative_SOC_deviation: 43.7765 Fuel Consumption: 106.8169 Total Degradation: 566.7332\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.741\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -417.90206170469423 SOC: 0.5405 Cumulative_SOC_deviation: 62.7910 Fuel Consumption: 105.7713 Total Degradation: 574.2037\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.997\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -538.0428888456944 SOC: 0.5210 Cumulative_SOC_deviation: 87.0789 Fuel Consumption: 105.1783 Total Degradation: 573.7976\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.011\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -384.4422985468102 SOC: 0.5514 Cumulative_SOC_deviation: 55.7618 Fuel Consumption: 107.2534 Total Degradation: 574.6590\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.771\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -362.34428942459056 SOC: 0.5630 Cumulative_SOC_deviation: 51.2420 Fuel Consumption: 107.6229 Total Degradation: 574.6342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.431\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -427.2360122199128 SOC: 0.5762 Cumulative_SOC_deviation: 63.9413 Fuel Consumption: 109.3872 Total Degradation: 566.2955\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.346\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -512.0400265385382 SOC: 0.5139 Cumulative_SOC_deviation: 82.1243 Fuel Consumption: 103.8045 Total Degradation: 572.1376\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.086\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -491.1507690159516 SOC: 0.5514 Cumulative_SOC_deviation: 77.1223 Fuel Consumption: 107.7799 Total Degradation: 574.2037\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.295\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -371.476978743876 SOC: 0.5559 Cumulative_SOC_deviation: 53.3143 Fuel Consumption: 106.4548 Total Degradation: 568.3976\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.524\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -383.0808739737996 SOC: 0.5650 Cumulative_SOC_deviation: 55.4517 Fuel Consumption: 107.4334 Total Degradation: 572.5441\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.277\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -291.65815568015967 SOC: 0.5736 Cumulative_SOC_deviation: 37.0170 Fuel Consumption: 107.6486 Total Degradation: 573.3883\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.301\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -374.10883479077097 SOC: 0.5504 Cumulative_SOC_deviation: 53.8979 Fuel Consumption: 106.1853 Total Degradation: 572.9842\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.384\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -424.9003107964484 SOC: 0.5401 Cumulative_SOC_deviation: 64.2070 Fuel Consumption: 105.7308 Total Degradation: 574.2109\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.180\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -476.9084435767836 SOC: 0.5555 Cumulative_SOC_deviation: 74.4661 Fuel Consumption: 106.7415 Total Degradation: 572.9602\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.459\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -352.4653242273643 SOC: 0.5701 Cumulative_SOC_deviation: 49.3310 Fuel Consumption: 107.2436 Total Degradation: 574.6222\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.788\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -268.8655020291108 SOC: 0.5881 Cumulative_SOC_deviation: 32.2490 Fuel Consumption: 108.5576 Total Degradation: 567.5774\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.423\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -327.1927997709479 SOC: 0.5737 Cumulative_SOC_deviation: 44.2485 Fuel Consumption: 107.2361 Total Degradation: 572.5633\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.977\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -376.34594562179996 SOC: 0.5777 Cumulative_SOC_deviation: 54.0718 Fuel Consumption: 107.5578 Total Degradation: 573.3979\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.195\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -284.3270828727841 SOC: 0.5801 Cumulative_SOC_deviation: 35.5781 Fuel Consumption: 107.4704 Total Degradation: 573.3715\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.141\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -398.2054766158912 SOC: 0.5746 Cumulative_SOC_deviation: 58.5540 Fuel Consumption: 107.1369 Total Degradation: 565.4970\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.141\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -300.08961041812273 SOC: 0.5811 Cumulative_SOC_deviation: 38.6827 Fuel Consumption: 107.8003 Total Degradation: 564.2439\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.315\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -324.76605247698063 SOC: 0.5832 Cumulative_SOC_deviation: 43.6360 Fuel Consumption: 107.8540 Total Degradation: 573.3811\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.338\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -417.20397388959196 SOC: 0.5427 Cumulative_SOC_deviation: 62.8186 Fuel Consumption: 104.9360 Total Degradation: 573.7852\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.399\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -279.6804721323485 SOC: 0.5827 Cumulative_SOC_deviation: 34.7227 Fuel Consumption: 107.0758 Total Degradation: 574.6149\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.500\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -269.35252430911737 SOC: 0.5751 Cumulative_SOC_deviation: 32.7350 Fuel Consumption: 106.6284 Total Degradation: 572.1352\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.120\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -513.7980167287639 SOC: 0.5343 Cumulative_SOC_deviation: 82.4411 Fuel Consumption: 103.9879 Total Degradation: 574.6173\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.432\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -414.5430585253206 SOC: 0.5796 Cumulative_SOC_deviation: 61.7761 Fuel Consumption: 107.4577 Total Degradation: 573.7876\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.771\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -251.138166076645 SOC: 0.5797 Cumulative_SOC_deviation: 29.0676 Fuel Consumption: 106.6449 Total Degradation: 574.6294\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.451\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -273.1522653867339 SOC: 0.5788 Cumulative_SOC_deviation: 33.5995 Fuel Consumption: 106.1310 Total Degradation: 573.7948\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.555\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -412.4111898792509 SOC: 0.5753 Cumulative_SOC_deviation: 61.3316 Fuel Consumption: 107.5352 Total Degradation: 572.1115\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.995\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -289.27600080929926 SOC: 0.5669 Cumulative_SOC_deviation: 36.8938 Fuel Consumption: 105.8791 Total Degradation: 572.9578\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.708\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -293.25817425364914 SOC: 0.5684 Cumulative_SOC_deviation: 37.6756 Fuel Consumption: 105.9750 Total Degradation: 574.6077\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.632\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -284.481840760282 SOC: 0.5729 Cumulative_SOC_deviation: 35.8749 Fuel Consumption: 106.1498 Total Degradation: 572.9674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.728\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -324.36367783284913 SOC: 0.5492 Cumulative_SOC_deviation: 44.2187 Fuel Consumption: 104.5548 Total Degradation: 572.5417\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.629\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -380.29036894088983 SOC: 0.5778 Cumulative_SOC_deviation: 55.1028 Fuel Consumption: 106.3776 Total Degradation: 574.6270\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.946\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -303.1208973643749 SOC: 0.5693 Cumulative_SOC_deviation: 39.6344 Fuel Consumption: 106.1005 Total Degradation: 572.9602\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.736\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -293.531277580418 SOC: 0.5673 Cumulative_SOC_deviation: 37.8603 Fuel Consumption: 105.3298 Total Degradation: 573.8048\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.462\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -292.9388378909516 SOC: 0.5725 Cumulative_SOC_deviation: 37.6514 Fuel Consumption: 105.7760 Total Degradation: 570.8821\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.135\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -279.4172119155612 SOC: 0.5679 Cumulative_SOC_deviation: 35.0376 Fuel Consumption: 105.2470 Total Degradation: 559.2435\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.829\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -318.8288654451545 SOC: 0.5825 Cumulative_SOC_deviation: 42.7088 Fuel Consumption: 106.5260 Total Degradation: 567.5606\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.390\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -325.61062071945867 SOC: 0.5581 Cumulative_SOC_deviation: 44.3599 Fuel Consumption: 105.1000 Total Degradation: 569.2177\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.854\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -355.3190894648618 SOC: 0.5694 Cumulative_SOC_deviation: 50.2058 Fuel Consumption: 105.7489 Total Degradation: 574.6101\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.908\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -343.1369223146439 SOC: 0.5675 Cumulative_SOC_deviation: 47.7708 Fuel Consumption: 105.6708 Total Degradation: 574.6197\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.626\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -307.2857969678993 SOC: 0.5745 Cumulative_SOC_deviation: 40.4286 Fuel Consumption: 106.3177 Total Degradation: 574.6149\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.527\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -327.07720975182116 SOC: 0.5792 Cumulative_SOC_deviation: 44.2887 Fuel Consumption: 106.9203 Total Degradation: 571.2910\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.071\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -442.7104700183381 SOC: 0.5825 Cumulative_SOC_deviation: 67.3718 Fuel Consumption: 107.8091 Total Degradation: 572.5321\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.363\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -291.7261139075271 SOC: 0.5662 Cumulative_SOC_deviation: 37.4353 Fuel Consumption: 105.6376 Total Degradation: 574.2037\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.057\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -287.5190587136231 SOC: 0.5653 Cumulative_SOC_deviation: 36.5537 Fuel Consumption: 105.8126 Total Degradation: 563.8326\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.670\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -309.7810208826829 SOC: 0.5751 Cumulative_SOC_deviation: 40.9482 Fuel Consumption: 106.2299 Total Degradation: 562.5723\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.533\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -321.65348141186627 SOC: 0.5765 Cumulative_SOC_deviation: 43.3749 Fuel Consumption: 106.0391 Total Degradation: 572.5417\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.684\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -268.1250980437547 SOC: 0.5658 Cumulative_SOC_deviation: 32.7221 Fuel Consumption: 105.4652 Total Degradation: 567.5774\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.694\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -314.86743673471295 SOC: 0.5683 Cumulative_SOC_deviation: 42.0214 Fuel Consumption: 105.9813 Total Degradation: 572.1376\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.711\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -324.14583694435424 SOC: 0.5687 Cumulative_SOC_deviation: 43.9822 Fuel Consumption: 105.5130 Total Degradation: 568.4024\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.589\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -334.1693031738457 SOC: 0.5674 Cumulative_SOC_deviation: 45.9619 Fuel Consumption: 105.6952 Total Degradation: 574.6077\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.940\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -311.7282899792954 SOC: 0.5666 Cumulative_SOC_deviation: 41.4295 Fuel Consumption: 105.7847 Total Degradation: 574.6149\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.150\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -343.27399225168426 SOC: 0.5572 Cumulative_SOC_deviation: 47.9713 Fuel Consumption: 104.8114 Total Degradation: 574.6149\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.701\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -530.7592528251643 SOC: 0.5724 Cumulative_SOC_deviation: 85.3808 Fuel Consumption: 106.3359 Total Degradation: 572.9506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.243\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -275.0530905410401 SOC: 0.5682 Cumulative_SOC_deviation: 33.9732 Fuel Consumption: 106.1744 Total Degradation: 570.8701\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.277\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -321.42760306172505 SOC: 0.5694 Cumulative_SOC_deviation: 43.3913 Fuel Consumption: 105.7319 Total Degradation: 574.6173\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.043\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -362.20392424148133 SOC: 0.5664 Cumulative_SOC_deviation: 51.5983 Fuel Consumption: 105.7115 Total Degradation: 574.1988\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.556\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -761.7007665678494 SOC: 0.5571 Cumulative_SOC_deviation: 131.7775 Fuel Consumption: 106.6421 Total Degradation: 574.6101\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.371\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -484.12330516915057 SOC: 0.5722 Cumulative_SOC_deviation: 76.1068 Fuel Consumption: 105.8006 Total Degradation: 574.6077\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.139\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -571.0041921537187 SOC: 0.5438 Cumulative_SOC_deviation: 93.8998 Fuel Consumption: 104.2336 Total Degradation: 573.7779\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.273\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -469.4112879366972 SOC: 0.5026 Cumulative_SOC_deviation: 74.1700 Fuel Consumption: 100.7162 Total Degradation: 574.6005\n",
      "\n",
      "model is saved..\n",
      "\n",
      "reward factor = 5.182889412082984\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.101\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -2726.1452940458917 SOC: 1.0000 Cumulative_SOC_deviation: 488.7339 Fuel Consumption: 193.0914 Total Degradation: 525.1098\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.108\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -2635.37190279475 SOC: 0.9994 Cumulative_SOC_deviation: 471.7012 Fuel Consumption: 190.5968 Total Degradation: 532.7005\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.266\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -2714.435095420171 SOC: 1.0000 Cumulative_SOC_deviation: 487.2800 Fuel Consumption: 188.9167 Total Degradation: 525.5427\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 35.300\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -2701.813906062758 SOC: 0.9997 Cumulative_SOC_deviation: 484.1945 Fuel Consumption: 192.2873 Total Degradation: 525.9636\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.560\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -2689.005413425987 SOC: 0.9994 Cumulative_SOC_deviation: 482.8529 Fuel Consumption: 186.4324 Total Degradation: 534.3817\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.703\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -2658.607801840419 SOC: 0.9992 Cumulative_SOC_deviation: 477.3001 Fuel Consumption: 184.8141 Total Degradation: 525.2610\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.473\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -2540.0886586946694 SOC: 0.9997 Cumulative_SOC_deviation: 455.9800 Fuel Consumption: 176.7945 Total Degradation: 517.0161\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.528\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -2609.7679303272766 SOC: 0.9984 Cumulative_SOC_deviation: 469.2571 Fuel Consumption: 177.6604 Total Degradation: 517.0546\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.316\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -2482.7267370005393 SOC: 0.9978 Cumulative_SOC_deviation: 446.7720 Fuel Consumption: 167.1566 Total Degradation: 517.5553\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.707\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -2579.974893855279 SOC: 0.9986 Cumulative_SOC_deviation: 463.6320 Fuel Consumption: 177.0213 Total Degradation: 515.8985\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.105\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -2419.6751324204133 SOC: 0.9989 Cumulative_SOC_deviation: 434.6882 Fuel Consumption: 166.7340 Total Degradation: 502.6705\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.734\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -2455.9178192654126 SOC: 1.0000 Cumulative_SOC_deviation: 441.3827 Fuel Consumption: 168.2802 Total Degradation: 507.6873\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.277\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -2325.9533390192864 SOC: 0.9996 Cumulative_SOC_deviation: 416.5556 Fuel Consumption: 166.9917 Total Degradation: 500.2826\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.181\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -2372.0486915133483 SOC: 0.9988 Cumulative_SOC_deviation: 425.9525 Fuel Consumption: 164.3838 Total Degradation: 495.7103\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.207\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -2378.1434974117988 SOC: 1.0000 Cumulative_SOC_deviation: 427.5044 Fuel Consumption: 162.4356 Total Degradation: 504.0387\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.857\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -2062.5928482383815 SOC: 0.9992 Cumulative_SOC_deviation: 368.1566 Fuel Consumption: 154.4779 Total Degradation: 482.0575\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.792\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -2143.5662567371432 SOC: 0.9968 Cumulative_SOC_deviation: 383.2488 Fuel Consumption: 157.2301 Total Degradation: 482.0455\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.432\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -2157.5596619618964 SOC: 0.9969 Cumulative_SOC_deviation: 386.0919 Fuel Consumption: 156.4879 Total Degradation: 476.2690\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.935\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -2044.2721490025292 SOC: 1.0000 Cumulative_SOC_deviation: 363.9416 Fuel Consumption: 158.0032 Total Degradation: 474.9899\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.518\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -1845.9742677047482 SOC: 0.9945 Cumulative_SOC_deviation: 326.0156 Fuel Consumption: 156.2715 Total Degradation: 454.2233\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.573\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -1667.190290512425 SOC: 0.9848 Cumulative_SOC_deviation: 292.2286 Fuel Consumption: 152.6018 Total Degradation: 446.3669\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.990\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -1743.016500000248 SOC: 0.9912 Cumulative_SOC_deviation: 306.8885 Fuel Consumption: 152.4472 Total Degradation: 455.9443\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.898\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1776.8232325881058 SOC: 0.9967 Cumulative_SOC_deviation: 313.2243 Fuel Consumption: 153.4162 Total Degradation: 445.0853\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.752\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1174.2324607931494 SOC: 0.9208 Cumulative_SOC_deviation: 197.7465 Fuel Consumption: 149.3342 Total Degradation: 418.4412\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.300\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1335.437179226227 SOC: 0.9736 Cumulative_SOC_deviation: 228.2074 Fuel Consumption: 152.6637 Total Degradation: 436.7943\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.208\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -964.2218134699937 SOC: 0.9159 Cumulative_SOC_deviation: 157.1788 Fuel Consumption: 149.5816 Total Degradation: 420.1702\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.770\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -589.4992699236657 SOC: 0.8069 Cumulative_SOC_deviation: 86.4122 Fuel Consumption: 141.6342 Total Degradation: 411.4319\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.149\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -895.4917177816494 SOC: 0.8882 Cumulative_SOC_deviation: 144.4449 Fuel Consumption: 146.8500 Total Degradation: 415.1290\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.980\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -876.5546000044595 SOC: 0.8804 Cumulative_SOC_deviation: 140.7374 Fuel Consumption: 147.1283 Total Degradation: 403.4948\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.906\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -501.2934485867943 SOC: 0.7384 Cumulative_SOC_deviation: 70.2985 Fuel Consumption: 136.9441 Total Degradation: 388.9463\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.214\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -466.63570111246935 SOC: 0.7610 Cumulative_SOC_deviation: 63.3331 Fuel Consumption: 138.3872 Total Degradation: 386.0364\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.239\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -414.17615697590907 SOC: 0.6619 Cumulative_SOC_deviation: 54.5857 Fuel Consumption: 131.2644 Total Degradation: 372.3009\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.766\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -679.860472504544 SOC: 0.5108 Cumulative_SOC_deviation: 108.3216 Fuel Consumption: 118.4414 Total Degradation: 361.8662\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.929\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -783.2536331373934 SOC: 0.5274 Cumulative_SOC_deviation: 127.9524 Fuel Consumption: 120.0907 Total Degradation: 359.7909\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.554\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -728.1145873950156 SOC: 0.5285 Cumulative_SOC_deviation: 117.2262 Fuel Consumption: 120.5442 Total Degradation: 349.3597\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.328\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -810.8154803704158 SOC: 0.5515 Cumulative_SOC_deviation: 132.8188 Fuel Consumption: 122.4306 Total Degradation: 356.0392\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.677\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -1280.692518431782 SOC: 0.3900 Cumulative_SOC_deviation: 225.8567 Fuel Consumption: 110.1023 Total Degradation: 339.3614\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.766\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1331.4745001528588 SOC: 0.3342 Cumulative_SOC_deviation: 236.4065 Fuel Consumption: 106.2059 Total Degradation: 333.1324\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.545\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1904.867886962494 SOC: 0.2380 Cumulative_SOC_deviation: 348.3372 Fuel Consumption: 99.4748 Total Degradation: 329.3968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.803\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1706.5502339159952 SOC: 0.2121 Cumulative_SOC_deviation: 310.3974 Fuel Consumption: 97.7946 Total Degradation: 320.2399\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.616\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1954.418252381383 SOC: 0.2229 Cumulative_SOC_deviation: 357.9626 Fuel Consumption: 99.1379 Total Degradation: 367.9780\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.364\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1844.2541710625437 SOC: 0.2510 Cumulative_SOC_deviation: 336.8256 Fuel Consumption: 98.5242 Total Degradation: 565.1149\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.990\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -1581.9826363740046 SOC: 0.3009 Cumulative_SOC_deviation: 285.4649 Fuel Consumption: 102.4494 Total Degradation: 553.9313\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.966\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -1694.8855672658055 SOC: 0.2706 Cumulative_SOC_deviation: 307.8318 Fuel Consumption: 99.4271 Total Degradation: 563.0393\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.532\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -1912.2704708291487 SOC: 0.2164 Cumulative_SOC_deviation: 350.4955 Fuel Consumption: 95.6912 Total Degradation: 568.8914\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.875\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -2045.906654167617 SOC: 0.1741 Cumulative_SOC_deviation: 376.7425 Fuel Consumption: 93.2918 Total Degradation: 572.2170\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.970\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -1557.9667338637057 SOC: 0.3025 Cumulative_SOC_deviation: 281.1580 Fuel Consumption: 100.7558 Total Degradation: 567.6267\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.201\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -2011.9608758323116 SOC: 0.1961 Cumulative_SOC_deviation: 370.1638 Fuel Consumption: 93.4429 Total Degradation: 564.3092\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.710\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -1316.5109033332642 SOC: 0.3344 Cumulative_SOC_deviation: 234.5232 Fuel Consumption: 101.0031 Total Degradation: 565.5234\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.353\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -1253.515179824024 SOC: 0.3274 Cumulative_SOC_deviation: 222.4689 Fuel Consumption: 100.4836 Total Degradation: 568.8474\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.302\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -1513.9790558164977 SOC: 0.2443 Cumulative_SOC_deviation: 273.7944 Fuel Consumption: 94.9331 Total Degradation: 564.7009\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.634\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -1353.172960264168 SOC: 0.2802 Cumulative_SOC_deviation: 242.2385 Fuel Consumption: 97.6776 Total Degradation: 566.3701\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.159\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -359.89058717093 SOC: 0.5489 Cumulative_SOC_deviation: 47.4962 Fuel Consumption: 113.7228 Total Degradation: 553.9413\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.733\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -278.8714633891555 SOC: 0.5746 Cumulative_SOC_deviation: 31.5174 Fuel Consumption: 115.5202 Total Degradation: 539.3776\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.761\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -189.7415355482599 SOC: 0.5941 Cumulative_SOC_deviation: 14.0826 Fuel Consumption: 116.7529 Total Degradation: 511.5567\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.784\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -173.610869841952 SOC: 0.5975 Cumulative_SOC_deviation: 10.7780 Fuel Consumption: 117.7497 Total Degradation: 494.5602\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.472\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -169.68944435933597 SOC: 0.5945 Cumulative_SOC_deviation: 10.2191 Fuel Consumption: 116.7249 Total Degradation: 491.2331\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.272\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -176.63656758740544 SOC: 0.5966 Cumulative_SOC_deviation: 11.7167 Fuel Consumption: 115.9100 Total Degradation: 501.6162\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.931\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -183.52470064442684 SOC: 0.5915 Cumulative_SOC_deviation: 13.1482 Fuel Consumption: 115.3789 Total Degradation: 518.2138\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.061\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -185.2370237464714 SOC: 0.5908 Cumulative_SOC_deviation: 13.5354 Fuel Consumption: 115.0843 Total Degradation: 493.6715\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.945\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -203.17333155649638 SOC: 0.5869 Cumulative_SOC_deviation: 17.1840 Fuel Consumption: 114.1108 Total Degradation: 520.2703\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.763\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -223.3536355178502 SOC: 0.5848 Cumulative_SOC_deviation: 20.8778 Fuel Consumption: 115.1463 Total Degradation: 531.4787\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.384\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -222.4121641712128 SOC: 0.5866 Cumulative_SOC_deviation: 21.1077 Fuel Consumption: 113.0132 Total Degradation: 571.7432\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.365\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -239.74802284368428 SOC: 0.5834 Cumulative_SOC_deviation: 24.3013 Fuel Consumption: 113.7969 Total Degradation: 553.9141\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.550\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -254.99491705030198 SOC: 0.5784 Cumulative_SOC_deviation: 27.5601 Fuel Consumption: 112.1538 Total Degradation: 550.6022\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.922\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -265.3351370283058 SOC: 0.5828 Cumulative_SOC_deviation: 29.3901 Fuel Consumption: 113.0097 Total Degradation: 551.3786\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.207\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -288.8325584995877 SOC: 0.5740 Cumulative_SOC_deviation: 34.2543 Fuel Consumption: 111.2963 Total Degradation: 572.5709\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.174\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -306.9522738280119 SOC: 0.5715 Cumulative_SOC_deviation: 37.7322 Fuel Consumption: 111.3903 Total Degradation: 572.9818\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.724\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -310.72194342811554 SOC: 0.5705 Cumulative_SOC_deviation: 38.4454 Fuel Consumption: 111.4637 Total Degradation: 572.9818\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.675\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -307.2058916250686 SOC: 0.5905 Cumulative_SOC_deviation: 37.4727 Fuel Consumption: 112.9892 Total Degradation: 570.9354\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.651\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -322.7241577723726 SOC: 0.5709 Cumulative_SOC_deviation: 40.8444 Fuel Consumption: 111.0321 Total Degradation: 568.8209\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.588\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -343.53248797759136 SOC: 0.5712 Cumulative_SOC_deviation: 45.0615 Fuel Consumption: 109.9835 Total Degradation: 572.9794\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.718\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -311.6580146728482 SOC: 0.5758 Cumulative_SOC_deviation: 38.9080 Fuel Consumption: 110.0022 Total Degradation: 570.9234\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.677\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -340.6382182301972 SOC: 0.5794 Cumulative_SOC_deviation: 44.4199 Fuel Consumption: 110.4150 Total Degradation: 570.5021\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.130\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -361.9842770759513 SOC: 0.5801 Cumulative_SOC_deviation: 48.5777 Fuel Consumption: 110.2116 Total Degradation: 573.3787\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.170\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -370.6908691994262 SOC: 0.5646 Cumulative_SOC_deviation: 50.5607 Fuel Consumption: 108.6405 Total Degradation: 569.2490\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.077\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -395.4650384439782 SOC: 0.5590 Cumulative_SOC_deviation: 55.4822 Fuel Consumption: 107.9071 Total Degradation: 573.0159\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.651\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -408.1671107060663 SOC: 0.5601 Cumulative_SOC_deviation: 57.7565 Fuel Consumption: 108.8213 Total Degradation: 572.5850\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.956\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -408.2138148442502 SOC: 0.5565 Cumulative_SOC_deviation: 57.9323 Fuel Consumption: 107.9572 Total Degradation: 573.8116\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.249\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -410.44889737652926 SOC: 0.5618 Cumulative_SOC_deviation: 58.2433 Fuel Consumption: 108.5805 Total Degradation: 571.3030\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.532\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -375.2519848404528 SOC: 0.5484 Cumulative_SOC_deviation: 51.8264 Fuel Consumption: 106.6413 Total Degradation: 574.6342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.513\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -424.44613766400107 SOC: 0.5786 Cumulative_SOC_deviation: 60.7964 Fuel Consumption: 109.3453 Total Degradation: 571.7219\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.295\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -414.1508242295148 SOC: 0.5609 Cumulative_SOC_deviation: 59.2285 Fuel Consumption: 107.1761 Total Degradation: 572.9722\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.014\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -481.2869969545786 SOC: 0.5408 Cumulative_SOC_deviation: 72.2956 Fuel Consumption: 106.5870 Total Degradation: 574.6542\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.893\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -485.087114296387 SOC: 0.5398 Cumulative_SOC_deviation: 72.9220 Fuel Consumption: 107.1404 Total Degradation: 573.8212\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.143\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -477.53371567084116 SOC: 0.5537 Cumulative_SOC_deviation: 71.4281 Fuel Consumption: 107.3297 Total Degradation: 572.1256\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.272\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -343.447495108393 SOC: 0.5466 Cumulative_SOC_deviation: 45.6567 Fuel Consumption: 106.8137 Total Degradation: 571.7191\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.377\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -514.6520160275376 SOC: 0.5449 Cumulative_SOC_deviation: 78.6930 Fuel Consumption: 106.7947 Total Degradation: 568.8113\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.893\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -542.3527054412164 SOC: 0.5416 Cumulative_SOC_deviation: 84.1074 Fuel Consumption: 106.4334 Total Degradation: 573.3963\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.580\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -557.0166216261536 SOC: 0.5392 Cumulative_SOC_deviation: 87.0251 Fuel Consumption: 105.9752 Total Degradation: 570.0644\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.850\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -561.3346486898345 SOC: 0.5346 Cumulative_SOC_deviation: 87.8624 Fuel Consumption: 105.9537 Total Degradation: 572.5513\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.994\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -561.966466612601 SOC: 0.5317 Cumulative_SOC_deviation: 88.0172 Fuel Consumption: 105.7830 Total Degradation: 571.2914\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.659\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -588.6963117343772 SOC: 0.5200 Cumulative_SOC_deviation: 93.4118 Fuel Consumption: 104.5532 Total Degradation: 574.2109\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.130\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -464.3424770436817 SOC: 0.5916 Cumulative_SOC_deviation: 68.3460 Fuel Consumption: 110.1126 Total Degradation: 570.0596\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.983\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -444.96505229970603 SOC: 0.5219 Cumulative_SOC_deviation: 65.6372 Fuel Consumption: 104.7746 Total Degradation: 572.5565\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.597\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -528.0987446397605 SOC: 0.5349 Cumulative_SOC_deviation: 81.5104 Fuel Consumption: 105.6396 Total Degradation: 567.5558\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.172\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -543.3521567253848 SOC: 0.5592 Cumulative_SOC_deviation: 83.9663 Fuel Consumption: 108.1642 Total Degradation: 572.5441\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.554\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -613.8218479797965 SOC: 0.5430 Cumulative_SOC_deviation: 97.8564 Fuel Consumption: 106.6431 Total Degradation: 573.8044\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.755\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -481.4939629433439 SOC: 0.5806 Cumulative_SOC_deviation: 71.4493 Fuel Consumption: 111.1801 Total Degradation: 569.6490\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.347\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -363.61756902950947 SOC: 0.5920 Cumulative_SOC_deviation: 48.6579 Fuel Consumption: 111.4292 Total Degradation: 574.6397\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.208\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -252.77919914879757 SOC: 0.5696 Cumulative_SOC_deviation: 28.0716 Fuel Consumption: 107.2873 Total Degradation: 572.5689\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.938\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -388.17102013074333 SOC: 0.5727 Cumulative_SOC_deviation: 53.9358 Fuel Consumption: 108.6279 Total Degradation: 571.2990\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.443\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -707.094990512468 SOC: 0.5763 Cumulative_SOC_deviation: 115.5214 Fuel Consumption: 108.3606 Total Degradation: 574.2092\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.048\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -297.2714875341148 SOC: 0.5870 Cumulative_SOC_deviation: 36.2831 Fuel Consumption: 109.2200 Total Degradation: 570.8845\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.561\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -480.6737201401684 SOC: 0.5837 Cumulative_SOC_deviation: 71.7421 Fuel Consumption: 108.8422 Total Degradation: 571.3054\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.203\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -401.01685723388425 SOC: 0.4989 Cumulative_SOC_deviation: 57.6130 Fuel Consumption: 102.4151 Total Degradation: 573.7996\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.669\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -595.3957422438579 SOC: 0.5132 Cumulative_SOC_deviation: 94.7236 Fuel Consumption: 104.4537 Total Degradation: 572.1432\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.784\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -438.18496045890794 SOC: 0.5881 Cumulative_SOC_deviation: 63.3566 Fuel Consumption: 109.8146 Total Degradation: 570.8781\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.330\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -254.73530200864272 SOC: 0.5765 Cumulative_SOC_deviation: 28.2716 Fuel Consumption: 108.2068 Total Degradation: 570.0451\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.064\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -491.6849213341029 SOC: 0.5369 Cumulative_SOC_deviation: 74.5868 Fuel Consumption: 105.1100 Total Degradation: 573.7852\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.102\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -438.6492850150553 SOC: 0.5119 Cumulative_SOC_deviation: 64.7434 Fuel Consumption: 103.0914 Total Degradation: 572.1208\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.834\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -440.4910173812753 SOC: 0.5658 Cumulative_SOC_deviation: 64.1235 Fuel Consumption: 108.1459 Total Degradation: 572.1328\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.194\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -307.720835936301 SOC: 0.5590 Cumulative_SOC_deviation: 38.7249 Fuel Consumption: 107.0137 Total Degradation: 572.5393\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.584\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -307.73011730256485 SOC: 0.5782 Cumulative_SOC_deviation: 38.6800 Fuel Consumption: 107.2558 Total Degradation: 573.3811\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.135\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -307.55866419877844 SOC: 0.5761 Cumulative_SOC_deviation: 38.5482 Fuel Consumption: 107.7678 Total Degradation: 572.5393\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.743\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -300.6955747651504 SOC: 0.5726 Cumulative_SOC_deviation: 37.2559 Fuel Consumption: 107.6023 Total Degradation: 573.3642\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.777\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -338.44235225643627 SOC: 0.5711 Cumulative_SOC_deviation: 44.5644 Fuel Consumption: 107.4702 Total Degradation: 567.5510\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.918\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -340.8830338709505 SOC: 0.5684 Cumulative_SOC_deviation: 45.1790 Fuel Consumption: 106.7252 Total Degradation: 570.0479\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.032\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -426.2943517554948 SOC: 0.5028 Cumulative_SOC_deviation: 62.4252 Fuel Consumption: 102.7514 Total Degradation: 567.5486\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.060\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -359.1107241373541 SOC: 0.5652 Cumulative_SOC_deviation: 48.6687 Fuel Consumption: 106.8663 Total Degradation: 569.2009\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.431\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -378.94158208728305 SOC: 0.5663 Cumulative_SOC_deviation: 52.4875 Fuel Consumption: 106.9048 Total Degradation: 568.3735\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.916\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -383.12925908988774 SOC: 0.5543 Cumulative_SOC_deviation: 53.4334 Fuel Consumption: 106.1900 Total Degradation: 569.2033\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.180\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -425.6225310834574 SOC: 0.5606 Cumulative_SOC_deviation: 61.5740 Fuel Consumption: 106.4911 Total Degradation: 570.4564\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.066\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -396.9019699404115 SOC: 0.5575 Cumulative_SOC_deviation: 56.1253 Fuel Consumption: 106.0108 Total Degradation: 569.6290\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.727\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -414.24769197724305 SOC: 0.5597 Cumulative_SOC_deviation: 59.4418 Fuel Consumption: 106.1674 Total Degradation: 566.3123\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.249\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -435.8856653880874 SOC: 0.5604 Cumulative_SOC_deviation: 63.5235 Fuel Consumption: 106.6503 Total Degradation: 567.9719\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.090\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -425.94753903874215 SOC: 0.5568 Cumulative_SOC_deviation: 61.6559 Fuel Consumption: 106.3918 Total Degradation: 567.5462\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.998\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -444.65098654546 SOC: 0.5585 Cumulative_SOC_deviation: 65.1867 Fuel Consumption: 106.7956 Total Degradation: 567.9622\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.183\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -454.0224258790409 SOC: 0.5498 Cumulative_SOC_deviation: 67.1154 Fuel Consumption: 106.1707 Total Degradation: 567.5437\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.889\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -472.3736853188249 SOC: 0.5538 Cumulative_SOC_deviation: 70.5958 Fuel Consumption: 106.4835 Total Degradation: 566.2962\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.954\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -508.4168778631443 SOC: 0.5448 Cumulative_SOC_deviation: 77.5677 Fuel Consumption: 106.3921 Total Degradation: 569.2137\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.802\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -535.9354913746789 SOC: 0.5395 Cumulative_SOC_deviation: 83.0878 Fuel Consumption: 105.3008 Total Degradation: 566.7219\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.357\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -565.9689333744773 SOC: 0.5359 Cumulative_SOC_deviation: 88.8528 Fuel Consumption: 105.4547 Total Degradation: 567.1452\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.159\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -557.2846435823684 SOC: 0.5358 Cumulative_SOC_deviation: 87.0521 Fuel Consumption: 106.1033 Total Degradation: 567.9606\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.873\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -572.3199895083371 SOC: 0.5307 Cumulative_SOC_deviation: 90.0179 Fuel Consumption: 105.7670 Total Degradation: 567.5493\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.546\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -566.7832220313984 SOC: 0.5291 Cumulative_SOC_deviation: 88.9967 Fuel Consumption: 105.5231 Total Degradation: 568.3870\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.183\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -568.9330049767508 SOC: 0.5284 Cumulative_SOC_deviation: 89.4928 Fuel Consumption: 105.1015 Total Degradation: 567.5569\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.545\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -626.5262984539078 SOC: 0.5346 Cumulative_SOC_deviation: 100.5213 Fuel Consumption: 105.5355 Total Degradation: 567.5493\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.714\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -630.9794314102135 SOC: 0.5191 Cumulative_SOC_deviation: 101.6006 Fuel Consumption: 104.3946 Total Degradation: 567.5469\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.609\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -699.6574328148387 SOC: 0.5063 Cumulative_SOC_deviation: 114.9231 Fuel Consumption: 104.0236 Total Degradation: 568.3791\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.198\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -727.9478308799755 SOC: 0.5086 Cumulative_SOC_deviation: 120.4153 Fuel Consumption: 103.8488 Total Degradation: 570.0355\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.391\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -588.1156133252879 SOC: 0.5107 Cumulative_SOC_deviation: 93.5491 Fuel Consumption: 103.2608 Total Degradation: 570.0435\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.728\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -679.5827534316217 SOC: 0.5151 Cumulative_SOC_deviation: 111.0989 Fuel Consumption: 103.7693 Total Degradation: 568.7968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.053\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -632.5584517995171 SOC: 0.5314 Cumulative_SOC_deviation: 101.8313 Fuel Consumption: 104.7780 Total Degradation: 568.7968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.843\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -591.828768866635 SOC: 0.5632 Cumulative_SOC_deviation: 93.6889 Fuel Consumption: 106.2497 Total Degradation: 569.2161\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.454\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -442.5803280288065 SOC: 0.5550 Cumulative_SOC_deviation: 65.0643 Fuel Consumption: 105.3592 Total Degradation: 570.8632\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.235\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -512.2820062323076 SOC: 0.5536 Cumulative_SOC_deviation: 78.6123 Fuel Consumption: 104.8432 Total Degradation: 567.9502\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.703\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -405.3829342496763 SOC: 0.5686 Cumulative_SOC_deviation: 57.7509 Fuel Consumption: 106.0665 Total Degradation: 568.3663\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.225\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -379.81948020021633 SOC: 0.5554 Cumulative_SOC_deviation: 52.8911 Fuel Consumption: 105.6910 Total Degradation: 569.6346\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.392\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -392.2038857695566 SOC: 0.5532 Cumulative_SOC_deviation: 55.2279 Fuel Consumption: 105.9638 Total Degradation: 569.2089\n",
      "\n",
      "model is saved..\n",
      "\n",
      "reward factor = 5.475446074798142\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.181\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -2871.7834083263333 SOC: 0.9999 Cumulative_SOC_deviation: 489.7423 Fuel Consumption: 190.2258 Total Degradation: 518.0334\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.338\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -2857.4479445621573 SOC: 0.9990 Cumulative_SOC_deviation: 487.3407 Fuel Consumption: 189.0404 Total Degradation: 529.3184\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 11.171\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -2827.607105802118 SOC: 1.0000 Cumulative_SOC_deviation: 481.7119 Fuel Consumption: 190.0196 Total Degradation: 525.5695\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer batch_normalization_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.086\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -2838.467940130912 SOC: 0.9997 Cumulative_SOC_deviation: 483.6823 Fuel Consumption: 190.0918 Total Degradation: 528.4770\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.986\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -2824.0552421879124 SOC: 1.0000 Cumulative_SOC_deviation: 481.0293 Fuel Consumption: 190.2051 Total Degradation: 531.4378\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.550\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -2741.0404719122075 SOC: 0.9996 Cumulative_SOC_deviation: 467.2724 Fuel Consumption: 182.5154 Total Degradation: 527.8273\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.860\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -2731.605065973165 SOC: 1.0000 Cumulative_SOC_deviation: 466.1065 Fuel Consumption: 179.4643 Total Degradation: 524.5062\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.059\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -2789.730328933407 SOC: 0.9987 Cumulative_SOC_deviation: 477.0835 Fuel Consumption: 177.4852 Total Degradation: 518.7778\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.853\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -2584.5531304396886 SOC: 1.0000 Cumulative_SOC_deviation: 440.8425 Fuel Consumption: 170.7438 Total Degradation: 515.5281\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.710\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -2602.137863013968 SOC: 0.9992 Cumulative_SOC_deviation: 444.5812 Fuel Consumption: 167.8576 Total Degradation: 506.7492\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.337\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -2658.7417313376604 SOC: 0.9994 Cumulative_SOC_deviation: 455.0790 Fuel Consumption: 166.9814 Total Degradation: 511.8314\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.140\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -2672.8081541436504 SOC: 0.9999 Cumulative_SOC_deviation: 457.6310 Fuel Consumption: 167.0742 Total Degradation: 505.1939\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.377\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -2465.130841167799 SOC: 1.0000 Cumulative_SOC_deviation: 420.5399 Fuel Consumption: 162.4871 Total Degradation: 504.0431\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.931\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -2371.9009246545397 SOC: 0.9996 Cumulative_SOC_deviation: 404.4411 Fuel Consumption: 157.4053 Total Degradation: 485.2824\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.590\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -2428.064875868641 SOC: 1.0000 Cumulative_SOC_deviation: 415.0920 Fuel Consumption: 155.2510 Total Degradation: 494.4733\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.341\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -2336.3027946938123 SOC: 0.9988 Cumulative_SOC_deviation: 397.4691 Fuel Consumption: 159.9823 Total Degradation: 489.4919\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.436\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -2400.338102884744 SOC: 1.0000 Cumulative_SOC_deviation: 409.8945 Fuel Consumption: 155.9828 Total Degradation: 471.6046\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.764\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -1973.2208215126511 SOC: 0.9909 Cumulative_SOC_deviation: 332.0655 Fuel Consumption: 155.0139 Total Degradation: 476.6968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.269\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -1925.0121485478908 SOC: 0.9995 Cumulative_SOC_deviation: 323.5302 Fuel Consumption: 153.5399 Total Degradation: 455.8588\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.264\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -1667.4566038492856 SOC: 0.9986 Cumulative_SOC_deviation: 276.0966 Fuel Consumption: 155.7045 Total Degradation: 459.6534\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.610\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -1631.764649822197 SOC: 0.9986 Cumulative_SOC_deviation: 269.9395 Fuel Consumption: 153.7254 Total Degradation: 455.9611\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.329\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -1565.6327598515516 SOC: 0.9798 Cumulative_SOC_deviation: 258.0574 Fuel Consumption: 152.6534 Total Degradation: 435.8955\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.436\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1406.0458984996733 SOC: 0.9561 Cumulative_SOC_deviation: 229.1619 Fuel Consumption: 151.2824 Total Degradation: 426.7342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.165\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1197.0819852936777 SOC: 0.9492 Cumulative_SOC_deviation: 191.0395 Fuel Consumption: 151.0557 Total Degradation: 430.9450\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.768\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1219.2564123436719 SOC: 0.9220 Cumulative_SOC_deviation: 195.4488 Fuel Consumption: 149.0868 Total Degradation: 420.1125\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.535\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -866.9980406261045 SOC: 0.9156 Cumulative_SOC_deviation: 131.1015 Fuel Consumption: 149.1590 Total Degradation: 419.7232\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.517\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -1410.7014537963817 SOC: 0.9508 Cumulative_SOC_deviation: 229.8691 Fuel Consumption: 152.0658 Total Degradation: 415.5671\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.069\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -588.80581611301 SOC: 0.7998 Cumulative_SOC_deviation: 81.8380 Fuel Consumption: 140.7065 Total Degradation: 399.7390\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.143\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -511.8855202098956 SOC: 0.7397 Cumulative_SOC_deviation: 68.4675 Fuel Consumption: 136.9956 Total Degradation: 402.2758\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.642\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -712.4850296921671 SOC: 0.8060 Cumulative_SOC_deviation: 104.4015 Fuel Consumption: 140.8405 Total Degradation: 402.2456\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.324\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -393.66350913755633 SOC: 0.6642 Cumulative_SOC_deviation: 48.0321 Fuel Consumption: 130.6666 Total Degradation: 383.1138\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.980\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -611.7898812204553 SOC: 0.6269 Cumulative_SOC_deviation: 88.2458 Fuel Consumption: 128.6050 Total Degradation: 368.5309\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.248\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -885.8179392858343 SOC: 0.4923 Cumulative_SOC_deviation: 140.2334 Fuel Consumption: 117.9775 Total Degradation: 361.4934\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.163\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -420.10410875338266 SOC: 0.6120 Cumulative_SOC_deviation: 53.5444 Fuel Consumption: 126.9248 Total Degradation: 374.8112\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.555\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -1185.6498631981929 SOC: 0.4803 Cumulative_SOC_deviation: 195.0436 Fuel Consumption: 117.6992 Total Degradation: 353.5371\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.454\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -750.7618118200746 SOC: 0.5523 Cumulative_SOC_deviation: 114.6245 Fuel Consumption: 123.1418 Total Degradation: 356.9047\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.522\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -1484.9240152013458 SOC: 0.3362 Cumulative_SOC_deviation: 251.8717 Fuel Consumption: 105.8142 Total Degradation: 341.0543\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.521\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1844.2010781718704 SOC: 0.3192 Cumulative_SOC_deviation: 317.3409 Fuel Consumption: 106.6182 Total Degradation: 333.9958\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.545\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1500.4699540187387 SOC: 0.2516 Cumulative_SOC_deviation: 255.7124 Fuel Consumption: 100.3304 Total Degradation: 314.7946\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.786\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -2100.305784853797 SOC: 0.1807 Cumulative_SOC_deviation: 365.9685 Fuel Consumption: 96.4649 Total Degradation: 326.5230\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.586\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1622.4857444246895 SOC: 0.2636 Cumulative_SOC_deviation: 277.6427 Fuel Consumption: 102.2683 Total Degradation: 326.9098\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.635\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1758.3042986764547 SOC: 0.1888 Cumulative_SOC_deviation: 303.6300 Fuel Consumption: 95.7949 Total Degradation: 311.4855\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.584\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -2399.2393414964386 SOC: 0.1221 Cumulative_SOC_deviation: 421.2321 Fuel Consumption: 92.8056 Total Degradation: 311.9136\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.740\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -1813.059176154831 SOC: 0.2185 Cumulative_SOC_deviation: 313.0333 Fuel Consumption: 99.0625 Total Degradation: 295.2121\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.898\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -3078.4707137167447 SOC: 0.0447 Cumulative_SOC_deviation: 545.8831 Fuel Consumption: 89.5174 Total Degradation: 283.5086\n",
      "\n",
      "battery power is 11563.788167568044(+) but condition is not avail\n",
      "elapsed_time: 71.486\n",
      "Episode: 46 Exploration P: 0.3195 Total reward: [-3719.9561972] SOC: -0.0014 Cumulative_SOC_deviation: 482.2181 Fuel Consumption: 82.8907 Total Degradation: 266.7971\n",
      "\n",
      "battery power is 1499.00861357018(+) but condition is not avail\n",
      "elapsed_time: 69.334\n",
      "Episode: 47 Exploration P: 0.3115 Total reward: [-3890.35109625] SOC: -0.0000 Cumulative_SOC_deviation: 513.2445 Fuel Consumption: 83.3950 Total Degradation: 264.1830\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.731\n",
      "Episode: 48 Exploration P: 0.3033 Total reward: -3053.1762588326997 SOC: 0.0265 Cumulative_SOC_deviation: 541.4216 Fuel Consumption: 88.6515 Total Degradation: 287.7148\n",
      "\n",
      "battery power is 4513.062336188976(+) but condition is not avail\n",
      "elapsed_time: 66.397\n",
      "Episode: 49 Exploration P: 0.2960 Total reward: [-3686.10928907] SOC: -0.0014 Cumulative_SOC_deviation: 477.0905 Fuel Consumption: 77.1194 Total Degradation: 245.3332\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.967\n",
      "Episode: 50 Exploration P: 0.2883 Total reward: -1676.0209940406396 SOC: 0.4998 Cumulative_SOC_deviation: 283.8102 Fuel Consumption: 122.0337 Total Degradation: 355.7329\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.013\n",
      "Episode: 51 Exploration P: 0.2807 Total reward: -1156.572740415347 SOC: 0.6604 Cumulative_SOC_deviation: 188.3224 Fuel Consumption: 125.4238 Total Degradation: 484.5635\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.187\n",
      "Episode: 52 Exploration P: 0.2734 Total reward: -166.00375638197445 SOC: 0.5928 Cumulative_SOC_deviation: 9.1048 Fuel Consumption: 116.1511 Total Degradation: 554.3154\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.410\n",
      "Episode: 53 Exploration P: 0.2663 Total reward: -218.506650815974 SOC: 0.6074 Cumulative_SOC_deviation: 18.1503 Fuel Consumption: 119.1256 Total Degradation: 503.2524\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.911\n",
      "Episode: 54 Exploration P: 0.2593 Total reward: -293.1208705220567 SOC: 0.5642 Cumulative_SOC_deviation: 32.4079 Fuel Consumption: 115.6729 Total Degradation: 450.0831\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.218\n",
      "Episode: 55 Exploration P: 0.2526 Total reward: -382.87004804157743 SOC: 0.5571 Cumulative_SOC_deviation: 48.9651 Fuel Consumption: 114.7641 Total Degradation: 453.8496\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.715\n",
      "Episode: 56 Exploration P: 0.2460 Total reward: -434.9985500501147 SOC: 0.5621 Cumulative_SOC_deviation: 57.9851 Fuel Consumption: 117.5043 Total Degradation: 426.0450\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.677\n",
      "Episode: 57 Exploration P: 0.2396 Total reward: -567.4496711785176 SOC: 0.5348 Cumulative_SOC_deviation: 82.2917 Fuel Consumption: 116.8659 Total Degradation: 405.2323\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.015\n",
      "Episode: 58 Exploration P: 0.2334 Total reward: -703.0586558649477 SOC: 0.5049 Cumulative_SOC_deviation: 107.5782 Fuel Consumption: 114.0199 Total Degradation: 412.2809\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.506\n",
      "Episode: 59 Exploration P: 0.2273 Total reward: -831.6243554180896 SOC: 0.4790 Cumulative_SOC_deviation: 131.5404 Fuel Consumption: 111.3822 Total Degradation: 409.7725\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.922\n",
      "Episode: 60 Exploration P: 0.2214 Total reward: -1004.4989783573585 SOC: 0.4772 Cumulative_SOC_deviation: 162.9980 Fuel Consumption: 112.0123 Total Degradation: 404.7922\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.039\n",
      "Episode: 61 Exploration P: 0.2157 Total reward: -996.5339342379402 SOC: 0.4516 Cumulative_SOC_deviation: 162.0815 Fuel Consumption: 109.0655 Total Degradation: 406.4008\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.682\n",
      "Episode: 62 Exploration P: 0.2101 Total reward: -1396.7965097933163 SOC: 0.3936 Cumulative_SOC_deviation: 235.6191 Fuel Consumption: 106.6769 Total Degradation: 391.0407\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.006\n",
      "Episode: 63 Exploration P: 0.2047 Total reward: -1557.4669078436846 SOC: 0.3708 Cumulative_SOC_deviation: 265.1725 Fuel Consumption: 105.5293 Total Degradation: 390.2065\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.704\n",
      "Episode: 64 Exploration P: 0.1994 Total reward: -1538.2679085178634 SOC: 0.4300 Cumulative_SOC_deviation: 260.7042 Fuel Consumption: 110.7959 Total Degradation: 397.2990\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.731\n",
      "Episode: 65 Exploration P: 0.1943 Total reward: -1237.8466742533224 SOC: 0.4271 Cumulative_SOC_deviation: 206.1281 Fuel Consumption: 109.2035 Total Degradation: 388.1351\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.319\n",
      "Episode: 66 Exploration P: 0.1893 Total reward: -1217.10578620542 SOC: 0.4591 Cumulative_SOC_deviation: 201.7815 Fuel Consumption: 112.2622 Total Degradation: 384.8393\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.844\n",
      "Episode: 67 Exploration P: 0.1845 Total reward: -1094.0102865660026 SOC: 0.4613 Cumulative_SOC_deviation: 179.2082 Fuel Consumption: 112.7657 Total Degradation: 341.9842\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.105\n",
      "Episode: 68 Exploration P: 0.1797 Total reward: -1344.1013180545847 SOC: 0.4133 Cumulative_SOC_deviation: 225.8877 Fuel Consumption: 107.2654 Total Degradation: 366.9076\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.376\n",
      "Episode: 69 Exploration P: 0.1751 Total reward: -1397.3605536897342 SOC: 0.4061 Cumulative_SOC_deviation: 235.9868 Fuel Consumption: 105.2277 Total Degradation: 427.9648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.220\n",
      "Episode: 70 Exploration P: 0.1707 Total reward: -1534.793174826971 SOC: 0.3566 Cumulative_SOC_deviation: 262.1729 Fuel Consumption: 99.2796 Total Degradation: 437.9490\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.151\n",
      "Episode: 71 Exploration P: 0.1663 Total reward: -1611.9159666739513 SOC: 0.4501 Cumulative_SOC_deviation: 274.5094 Fuel Consumption: 108.8545 Total Degradation: 423.7750\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.156\n",
      "Episode: 72 Exploration P: 0.1621 Total reward: -1228.3545821500638 SOC: 0.5344 Cumulative_SOC_deviation: 203.3554 Fuel Consumption: 114.8929 Total Degradation: 491.1244\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.943\n",
      "Episode: 73 Exploration P: 0.1580 Total reward: -616.2425399063735 SOC: 0.5462 Cumulative_SOC_deviation: 92.7811 Fuel Consumption: 108.2244 Total Degradation: 560.5351\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.130\n",
      "Episode: 74 Exploration P: 0.1540 Total reward: -487.05364550244207 SOC: 0.5456 Cumulative_SOC_deviation: 69.0013 Fuel Consumption: 109.2407 Total Degradation: 563.0152\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.214\n",
      "Episode: 75 Exploration P: 0.1501 Total reward: -496.1513011780412 SOC: 0.5434 Cumulative_SOC_deviation: 70.8318 Fuel Consumption: 108.3158 Total Degradation: 569.2614\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.068\n",
      "Episode: 76 Exploration P: 0.1463 Total reward: -430.5336866365452 SOC: 0.5384 Cumulative_SOC_deviation: 58.8237 Fuel Consumption: 108.4475 Total Degradation: 570.9062\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.471\n",
      "Episode: 77 Exploration P: 0.1426 Total reward: -489.0925124296149 SOC: 0.5367 Cumulative_SOC_deviation: 69.4978 Fuel Consumption: 108.5608 Total Degradation: 555.1215\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.143\n",
      "Episode: 78 Exploration P: 0.1390 Total reward: -436.48276898664176 SOC: 0.5747 Cumulative_SOC_deviation: 59.5528 Fuel Consumption: 110.4046 Total Degradation: 560.9488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.409\n",
      "Episode: 79 Exploration P: 0.1355 Total reward: -326.143391825102 SOC: 0.5667 Cumulative_SOC_deviation: 39.6351 Fuel Consumption: 109.1234 Total Degradation: 568.0224\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.059\n",
      "Episode: 80 Exploration P: 0.1321 Total reward: -320.35698598822165 SOC: 0.5802 Cumulative_SOC_deviation: 38.3091 Fuel Consumption: 110.5976 Total Degradation: 558.4763\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.209\n",
      "Episode: 81 Exploration P: 0.1288 Total reward: -237.78358432136517 SOC: 0.5889 Cumulative_SOC_deviation: 23.2134 Fuel Consumption: 110.6797 Total Degradation: 565.9275\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.230\n",
      "Episode: 82 Exploration P: 0.1256 Total reward: -440.1039614395615 SOC: 0.5242 Cumulative_SOC_deviation: 60.7334 Fuel Consumption: 107.5617 Total Degradation: 529.3649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.073\n",
      "Episode: 83 Exploration P: 0.1224 Total reward: -383.47659253893914 SOC: 0.5835 Cumulative_SOC_deviation: 49.8499 Fuel Consumption: 110.5264 Total Degradation: 518.9618\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.379\n",
      "Episode: 84 Exploration P: 0.1194 Total reward: -386.8863593520106 SOC: 0.5547 Cumulative_SOC_deviation: 50.8516 Fuel Consumption: 108.4509 Total Degradation: 550.5777\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.404\n",
      "Episode: 85 Exploration P: 0.1164 Total reward: -313.78425136473624 SOC: 0.5434 Cumulative_SOC_deviation: 36.7608 Fuel Consumption: 112.5026 Total Degradation: 491.5309\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.210\n",
      "Episode: 86 Exploration P: 0.1135 Total reward: -708.748057354344 SOC: 0.5199 Cumulative_SOC_deviation: 109.7731 Fuel Consumption: 107.6915 Total Degradation: 508.9711\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.632\n",
      "Episode: 87 Exploration P: 0.1107 Total reward: -617.7013222941795 SOC: 0.5748 Cumulative_SOC_deviation: 92.6755 Fuel Consumption: 110.2615 Total Degradation: 542.1933\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.738\n",
      "Episode: 88 Exploration P: 0.1080 Total reward: -289.2845226874327 SOC: 0.5761 Cumulative_SOC_deviation: 32.9200 Fuel Consumption: 109.0326 Total Degradation: 567.5919\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.954\n",
      "Episode: 89 Exploration P: 0.1054 Total reward: -597.5490674775062 SOC: 0.4756 Cumulative_SOC_deviation: 89.5771 Fuel Consumption: 107.0746 Total Degradation: 485.6923\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.324\n",
      "Episode: 90 Exploration P: 0.1028 Total reward: -751.4211957248672 SOC: 0.5726 Cumulative_SOC_deviation: 116.0414 Fuel Consumption: 116.0426 Total Degradation: 518.5485\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.022\n",
      "Episode: 91 Exploration P: 0.1003 Total reward: -329.8681475338442 SOC: 0.6249 Cumulative_SOC_deviation: 39.6630 Fuel Consumption: 112.6953 Total Degradation: 557.6128\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.050\n",
      "Episode: 92 Exploration P: 0.0978 Total reward: -325.0195106715942 SOC: 0.5898 Cumulative_SOC_deviation: 39.3891 Fuel Consumption: 109.3467 Total Degradation: 559.6861\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.681\n",
      "Episode: 93 Exploration P: 0.0954 Total reward: -219.00615711882946 SOC: 0.5859 Cumulative_SOC_deviation: 20.1515 Fuel Consumption: 108.6678 Total Degradation: 546.8160\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.411\n",
      "Episode: 94 Exploration P: 0.0931 Total reward: -246.03965531989851 SOC: 0.5337 Cumulative_SOC_deviation: 25.6226 Fuel Consumption: 105.7447 Total Degradation: 524.7992\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.443\n",
      "Episode: 95 Exploration P: 0.0909 Total reward: -421.0010763929228 SOC: 0.6375 Cumulative_SOC_deviation: 55.9101 Fuel Consumption: 114.8682 Total Degradation: 548.4515\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.321\n",
      "Episode: 96 Exploration P: 0.0887 Total reward: -570.7046191035745 SOC: 0.5596 Cumulative_SOC_deviation: 84.0156 Fuel Consumption: 110.6819 Total Degradation: 501.8855\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.432\n",
      "Episode: 97 Exploration P: 0.0866 Total reward: -239.45260264222352 SOC: 0.5878 Cumulative_SOC_deviation: 23.8385 Fuel Consumption: 108.9263 Total Degradation: 516.8645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.611\n",
      "Episode: 98 Exploration P: 0.0845 Total reward: -324.0293195020978 SOC: 0.5862 Cumulative_SOC_deviation: 39.2347 Fuel Consumption: 109.2017 Total Degradation: 561.7669\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.079\n",
      "Episode: 99 Exploration P: 0.0825 Total reward: -279.1270550633941 SOC: 0.5802 Cumulative_SOC_deviation: 31.2269 Fuel Consumption: 108.1460 Total Degradation: 558.4498\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.177\n",
      "Episode: 100 Exploration P: 0.0805 Total reward: -350.2779819257926 SOC: 0.5949 Cumulative_SOC_deviation: 43.7927 Fuel Consumption: 110.4934 Total Degradation: 528.9124\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.954\n",
      "Episode: 101 Exploration P: 0.0786 Total reward: -256.4694933053749 SOC: 0.5757 Cumulative_SOC_deviation: 27.2231 Fuel Consumption: 107.4108 Total Degradation: 530.9876\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.356\n",
      "Episode: 102 Exploration P: 0.0767 Total reward: -230.21176661150184 SOC: 0.5806 Cumulative_SOC_deviation: 21.8927 Fuel Consumption: 110.3394 Total Degradation: 485.2541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.892\n",
      "Episode: 103 Exploration P: 0.0749 Total reward: -284.49325891693996 SOC: 0.5648 Cumulative_SOC_deviation: 32.2326 Fuel Consumption: 108.0056 Total Degradation: 507.3023\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.800\n",
      "Episode: 104 Exploration P: 0.0732 Total reward: -368.5097965137537 SOC: 0.5611 Cumulative_SOC_deviation: 47.5494 Fuel Consumption: 108.1556 Total Degradation: 499.8167\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.973\n",
      "Episode: 105 Exploration P: 0.0715 Total reward: -516.387456831871 SOC: 0.5758 Cumulative_SOC_deviation: 73.8898 Fuel Consumption: 111.8080 Total Degradation: 502.3084\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.930\n",
      "Episode: 106 Exploration P: 0.0698 Total reward: -309.9239966080763 SOC: 0.5704 Cumulative_SOC_deviation: 36.7278 Fuel Consumption: 108.8230 Total Degradation: 480.6936\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.732\n",
      "Episode: 107 Exploration P: 0.0682 Total reward: -368.74613511311264 SOC: 0.5613 Cumulative_SOC_deviation: 48.0476 Fuel Consumption: 105.6642 Total Degradation: 518.5361\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.770\n",
      "Episode: 108 Exploration P: 0.0666 Total reward: -362.45327269520124 SOC: 0.5718 Cumulative_SOC_deviation: 46.7087 Fuel Consumption: 106.7025 Total Degradation: 502.2916\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.769\n",
      "Episode: 109 Exploration P: 0.0651 Total reward: -391.19022051596426 SOC: 0.5776 Cumulative_SOC_deviation: 51.4156 Fuel Consumption: 109.6670 Total Degradation: 471.5175\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.975\n",
      "Episode: 110 Exploration P: 0.0636 Total reward: -496.26960505528194 SOC: 0.3769 Cumulative_SOC_deviation: 73.0327 Fuel Consumption: 96.3828 Total Degradation: 461.9882\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.390\n",
      "Episode: 111 Exploration P: 0.0621 Total reward: -981.0133561212748 SOC: 0.5751 Cumulative_SOC_deviation: 157.8353 Fuel Consumption: 116.7947 Total Degradation: 497.2864\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.378\n",
      "Episode: 112 Exploration P: 0.0607 Total reward: -419.4346113759804 SOC: 0.5379 Cumulative_SOC_deviation: 56.7893 Fuel Consumption: 108.4876 Total Degradation: 481.0780\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.247\n",
      "Episode: 113 Exploration P: 0.0593 Total reward: -487.4882469465924 SOC: 0.5607 Cumulative_SOC_deviation: 68.8472 Fuel Consumption: 110.5190 Total Degradation: 487.7676\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.173\n",
      "Episode: 114 Exploration P: 0.0580 Total reward: -400.73672064620024 SOC: 0.5538 Cumulative_SOC_deviation: 53.2628 Fuel Consumption: 109.0994 Total Degradation: 459.8620\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.290\n",
      "Episode: 115 Exploration P: 0.0567 Total reward: -442.6278407724384 SOC: 0.5183 Cumulative_SOC_deviation: 60.7915 Fuel Consumption: 109.7675 Total Degradation: 429.5285\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.118\n",
      "Episode: 116 Exploration P: 0.0554 Total reward: -479.4095321647338 SOC: 0.5408 Cumulative_SOC_deviation: 67.0157 Fuel Consumption: 112.4687 Total Degradation: 417.4932\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.548\n",
      "Episode: 117 Exploration P: 0.0542 Total reward: -369.865470871998 SOC: 0.5670 Cumulative_SOC_deviation: 47.5084 Fuel Consumption: 109.7357 Total Degradation: 433.6914\n",
      "\n",
      "battery power is 9642.042427194741(+) but condition is not avail\n",
      "elapsed_time: 22.868\n",
      "Episode: 118 Exploration P: 0.0538 Total reward: [-1788.07927975] SOC: -0.0004 Cumulative_SOC_deviation: 142.5056 Fuel Consumption: 11.0856 Total Degradation: 86.3940\n",
      "\n",
      "battery power is 24774.302920551192(+) but condition is not avail\n",
      "elapsed_time: 22.390\n",
      "Episode: 119 Exploration P: 0.0534 Total reward: [-1777.1334721] SOC: -0.0018 Cumulative_SOC_deviation: 140.9455 Fuel Consumption: 8.6897 Total Degradation: 26.4552\n",
      "\n",
      "battery power is 9491.754015579985(+) but condition is not avail\n",
      "elapsed_time: 23.749\n",
      "Episode: 120 Exploration P: 0.0530 Total reward: [-1822.56703704] SOC: -0.0016 Cumulative_SOC_deviation: 148.3764 Fuel Consumption: 13.4346 Total Degradation: 38.6323\n",
      "\n",
      "battery power is 8481.396218467664(+) but condition is not avail\n",
      "elapsed_time: 23.565\n",
      "Episode: 121 Exploration P: 0.0526 Total reward: [-1819.02738348] SOC: -0.0001 Cumulative_SOC_deviation: 147.7762 Fuel Consumption: 13.1735 Total Degradation: 35.2794\n",
      "\n",
      "battery power is 8240.409922130348(+) but condition is not avail\n",
      "elapsed_time: 23.370\n",
      "Episode: 122 Exploration P: 0.0522 Total reward: [-1821.99424083] SOC: -0.0012 Cumulative_SOC_deviation: 148.5420 Fuel Consumption: 11.9530 Total Degradation: 35.6811\n",
      "\n",
      "battery power is 9399.485516747744(+) but condition is not avail\n",
      "elapsed_time: 23.583\n",
      "Episode: 123 Exploration P: 0.0518 Total reward: [-1804.57127895] SOC: -0.0003 Cumulative_SOC_deviation: 145.1816 Fuel Consumption: 12.9253 Total Degradation: 34.4424\n",
      "\n",
      "battery power is 9399.485516747744(+) but condition is not avail\n",
      "elapsed_time: 23.358\n",
      "Episode: 124 Exploration P: 0.0514 Total reward: [-1837.17044325] SOC: -0.0012 Cumulative_SOC_deviation: 151.2362 Fuel Consumption: 12.3773 Total Degradation: 28.9899\n",
      "\n",
      "battery power is 10977.001209334117(+) but condition is not avail\n",
      "elapsed_time: 22.970\n",
      "Episode: 125 Exploration P: 0.0510 Total reward: [-1806.58437002] SOC: -0.0011 Cumulative_SOC_deviation: 145.8225 Fuel Consumption: 11.4334 Total Degradation: 35.6667\n",
      "\n",
      "battery power is 8036.667345275428(+) but condition is not avail\n",
      "elapsed_time: 23.228\n",
      "Episode: 126 Exploration P: 0.0506 Total reward: [-1820.56778678] SOC: -0.0004 Cumulative_SOC_deviation: 148.2639 Fuel Consumption: 12.0449 Total Degradation: 31.0752\n",
      "\n",
      "battery power is 16872.29964873525(+) but condition is not avail\n",
      "elapsed_time: 22.590\n",
      "Episode: 127 Exploration P: 0.0502 Total reward: [-1779.5646428] SOC: -0.0002 Cumulative_SOC_deviation: 141.0482 Fuel Consumption: 10.5497 Total Degradation: 26.8854\n",
      "\n",
      "battery power is 8240.409922130348(+) but condition is not avail\n",
      "elapsed_time: 23.213\n",
      "Episode: 128 Exploration P: 0.0498 Total reward: [-1823.81717395] SOC: -0.0004 Cumulative_SOC_deviation: 148.8177 Fuel Consumption: 12.2623 Total Degradation: 34.4304\n",
      "\n",
      "battery power is 9491.754015579985(+) but condition is not avail\n",
      "elapsed_time: 23.691\n",
      "Episode: 129 Exploration P: 0.0494 Total reward: [-1847.90264578] SOC: -0.0013 Cumulative_SOC_deviation: 153.0409 Fuel Consumption: 13.2284 Total Degradation: 34.4400\n",
      "\n",
      "battery power is 9642.042427194741(+) but condition is not avail\n",
      "elapsed_time: 22.732\n",
      "Episode: 130 Exploration P: 0.0491 Total reward: [-1785.26343069] SOC: -0.0003 Cumulative_SOC_deviation: 142.0000 Fuel Consumption: 11.0376 Total Degradation: 30.6547\n",
      "\n",
      "battery power is 7886.327523269496(+) but condition is not avail\n",
      "elapsed_time: 23.062\n",
      "Episode: 131 Exploration P: 0.0487 Total reward: [-1792.83064079] SOC: -0.0009 Cumulative_SOC_deviation: 143.1879 Fuel Consumption: 12.1043 Total Degradation: 30.2526\n",
      "\n",
      "battery power is 8551.059668951773(+) but condition is not avail\n",
      "elapsed_time: 23.190\n",
      "Episode: 132 Exploration P: 0.0483 Total reward: [-1823.1681526] SOC: -0.0001 Cumulative_SOC_deviation: 148.8102 Fuel Consumption: 11.6524 Total Degradation: 30.2406\n",
      "\n",
      "battery power is 13575.510241926464(+) but condition is not avail\n",
      "elapsed_time: 22.611\n",
      "Episode: 133 Exploration P: 0.0480 Total reward: [-1768.58799142] SOC: -0.0008 Cumulative_SOC_deviation: 139.0082 Fuel Consumption: 10.7464 Total Degradation: 28.1385\n",
      "\n",
      "battery power is 9566.487376783774(+) but condition is not avail\n",
      "elapsed_time: 22.985\n",
      "Episode: 134 Exploration P: 0.0476 Total reward: [-1815.90639055] SOC: -0.0011 Cumulative_SOC_deviation: 147.5552 Fuel Consumption: 11.2677 Total Degradation: 30.2310\n",
      "\n",
      "battery power is 10977.001209334117(+) but condition is not avail\n",
      "elapsed_time: 23.000\n",
      "Episode: 135 Exploration P: 0.0473 Total reward: [-1820.43702733] SOC: -0.0006 Cumulative_SOC_deviation: 148.2936 Fuel Consumption: 11.7530 Total Degradation: 28.5618\n",
      "\n",
      "battery power is 9642.042427194741(+) but condition is not avail\n",
      "elapsed_time: 22.746\n",
      "Episode: 136 Exploration P: 0.0469 Total reward: [-1794.34283639] SOC: -0.0022 Cumulative_SOC_deviation: 143.7185 Fuel Consumption: 10.7180 Total Degradation: 30.2238\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery power is 14740.315499693399(+) but condition is not avail\n",
      "elapsed_time: 22.706\n",
      "Episode: 137 Exploration P: 0.0466 Total reward: [-1787.60416385] SOC: -0.0002 Cumulative_SOC_deviation: 142.5012 Fuel Consumption: 10.6339 Total Degradation: 29.3868\n",
      "\n",
      "battery power is 9566.487376783774(+) but condition is not avail\n",
      "elapsed_time: 23.031\n",
      "Episode: 138 Exploration P: 0.0463 Total reward: [-1796.07285928] SOC: -0.0005 Cumulative_SOC_deviation: 143.9079 Fuel Consumption: 11.4017 Total Degradation: 28.9851\n",
      "\n",
      "battery power is 17785.909242589274(+) but condition is not avail\n",
      "elapsed_time: 22.500\n",
      "Episode: 139 Exploration P: 0.0459 Total reward: [-1778.73944069] SOC: -0.0012 Cumulative_SOC_deviation: 140.9759 Fuel Consumption: 10.1263 Total Degradation: 28.1361\n",
      "\n",
      "battery power is 10977.001209334117(+) but condition is not avail\n",
      "elapsed_time: 23.013\n",
      "Episode: 140 Exploration P: 0.0456 Total reward: [-1809.42611786] SOC: -0.0015 Cumulative_SOC_deviation: 146.3569 Fuel Consumption: 11.3510 Total Degradation: 28.1385\n",
      "\n",
      "battery power is 11019.461177283047(+) but condition is not avail\n",
      "elapsed_time: 22.861\n",
      "Episode: 141 Exploration P: 0.0453 Total reward: [-1789.36055381] SOC: -0.0005 Cumulative_SOC_deviation: 142.7108 Fuel Consumption: 11.2446 Total Degradation: 30.2286\n",
      "\n",
      "battery power is 7185.205061596161(+) but condition is not avail\n",
      "elapsed_time: 23.140\n",
      "Episode: 142 Exploration P: 0.0449 Total reward: [-1809.35171778] SOC: -0.0006 Cumulative_SOC_deviation: 146.2650 Fuel Consumption: 11.7753 Total Degradation: 29.8221\n",
      "\n",
      "battery power is 11354.537258226766(+) but condition is not avail\n",
      "elapsed_time: 23.553\n",
      "Episode: 143 Exploration P: 0.0446 Total reward: [-1840.37143455] SOC: -0.0002 Cumulative_SOC_deviation: 151.6834 Fuel Consumption: 13.1245 Total Degradation: 36.9559\n",
      "\n",
      "battery power is 7185.205061596161(+) but condition is not avail\n",
      "elapsed_time: 23.200\n",
      "Episode: 144 Exploration P: 0.0443 Total reward: [-1820.39915067] SOC: -0.0000 Cumulative_SOC_deviation: 148.3197 Fuel Consumption: 11.5691 Total Degradation: 29.3964\n",
      "\n",
      "battery power is 9566.487376783774(+) but condition is not avail\n",
      "elapsed_time: 22.961\n",
      "Episode: 145 Exploration P: 0.0439 Total reward: [-1817.41912435] SOC: -0.0006 Cumulative_SOC_deviation: 147.8385 Fuel Consumption: 11.2264 Total Degradation: 28.9755\n",
      "\n",
      "battery power is 7271.183059193313(+) but condition is not avail\n",
      "elapsed_time: 22.950\n",
      "Episode: 146 Exploration P: 0.0436 Total reward: [-1800.22379161] SOC: -0.0011 Cumulative_SOC_deviation: 144.6799 Fuel Consumption: 11.3287 Total Degradation: 25.6443\n",
      "\n",
      "battery power is 9017.906336131611(+) but condition is not avail\n",
      "elapsed_time: 23.550\n",
      "Episode: 147 Exploration P: 0.0433 Total reward: [-1826.12983964] SOC: -0.0009 Cumulative_SOC_deviation: 149.0928 Fuel Consumption: 13.0713 Total Degradation: 31.9459\n",
      "\n",
      "battery power is 7271.183059193313(+) but condition is not avail\n",
      "elapsed_time: 22.999\n",
      "Episode: 148 Exploration P: 0.0430 Total reward: [-1792.34016285] SOC: -0.0012 Cumulative_SOC_deviation: 143.1988 Fuel Consumption: 11.5555 Total Degradation: 31.4913\n",
      "\n",
      "battery power is 13575.510241926464(+) but condition is not avail\n",
      "elapsed_time: 22.692\n",
      "Episode: 149 Exploration P: 0.0427 Total reward: [-1811.04642062] SOC: -0.0007 Cumulative_SOC_deviation: 146.7417 Fuel Consumption: 10.8598 Total Degradation: 23.9442\n",
      "\n",
      "battery power is 23324.440768418353(+) but condition is not avail\n",
      "elapsed_time: 22.529\n",
      "Episode: 150 Exploration P: 0.0424 Total reward: [-1795.83227495] SOC: -0.0015 Cumulative_SOC_deviation: 144.2508 Fuel Consumption: 9.2888 Total Degradation: 21.4377\n",
      "\n",
      "model is saved..\n",
      "\n",
      "reward factor = 8.479120367254383\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.586\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -4353.775631919823 SOC: 1.0000 Cumulative_SOC_deviation: 491.1499 Fuel Consumption: 189.2568 Total Degradation: 530.1727\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.405\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -4264.68170049078 SOC: 1.0000 Cumulative_SOC_deviation: 481.0472 Fuel Consumption: 185.8243 Total Degradation: 523.5031\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.370\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -4218.938427872769 SOC: 0.9983 Cumulative_SOC_deviation: 475.2804 Fuel Consumption: 188.9785 Total Degradation: 526.8374\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_18 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_19 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 29.337\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -4276.776406801265 SOC: 1.0000 Cumulative_SOC_deviation: 481.9424 Fuel Consumption: 190.3288 Total Degradation: 522.2191\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.838\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -4265.2291836247805 SOC: 1.0000 Cumulative_SOC_deviation: 480.5951 Fuel Consumption: 190.2051 Total Degradation: 528.0894\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.985\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -4270.913197894734 SOC: 0.9993 Cumulative_SOC_deviation: 481.2351 Fuel Consumption: 190.4628 Total Degradation: 524.8280\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.987\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -4109.74817903013 SOC: 1.0000 Cumulative_SOC_deviation: 463.8824 Fuel Consumption: 176.4338 Total Degradation: 508.2472\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.235\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -4246.334562607118 SOC: 1.0000 Cumulative_SOC_deviation: 479.0147 Fuel Consumption: 184.7110 Total Degradation: 520.3937\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.573\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -4091.613413696773 SOC: 0.9997 Cumulative_SOC_deviation: 462.2104 Fuel Consumption: 172.4755 Total Degradation: 522.1640\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.319\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -3927.651086977476 SOC: 0.9975 Cumulative_SOC_deviation: 442.9085 Fuel Consumption: 172.1766 Total Degradation: 501.7313\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.326\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -4063.1751371979217 SOC: 1.0000 Cumulative_SOC_deviation: 459.3866 Fuel Consumption: 167.9813 Total Degradation: 514.3568\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.530\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -3840.389024387827 SOC: 1.0000 Cumulative_SOC_deviation: 433.4401 Fuel Consumption: 165.1981 Total Degradation: 500.2113\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.595\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -3820.146008869093 SOC: 0.9994 Cumulative_SOC_deviation: 431.4527 Fuel Consumption: 161.8068 Total Degradation: 503.5404\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.301\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -3902.65166283751 SOC: 0.9999 Cumulative_SOC_deviation: 440.9060 Fuel Consumption: 164.1570 Total Degradation: 496.0700\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.390\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -3756.0559030038844 SOC: 0.9986 Cumulative_SOC_deviation: 424.1299 Fuel Consumption: 159.8071 Total Degradation: 491.1679\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.522\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -3174.725374154216 SOC: 0.9925 Cumulative_SOC_deviation: 356.0827 Fuel Consumption: 155.4571 Total Degradation: 466.6315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.150\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -3344.141007290325 SOC: 1.0000 Cumulative_SOC_deviation: 376.2126 Fuel Consumption: 154.1893 Total Degradation: 483.3423\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.721\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -3425.4239653147683 SOC: 0.9991 Cumulative_SOC_deviation: 385.8900 Fuel Consumption: 153.4162 Total Degradation: 475.8157\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.249\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -2948.738556467162 SOC: 0.9933 Cumulative_SOC_deviation: 329.6263 Fuel Consumption: 153.7976 Total Degradation: 477.0833\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.835\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -3210.9842056306666 SOC: 0.9978 Cumulative_SOC_deviation: 360.7042 Fuel Consumption: 152.5297 Total Degradation: 472.5386\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.718\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -2857.329914769159 SOC: 0.9927 Cumulative_SOC_deviation: 318.9237 Fuel Consumption: 153.1379 Total Degradation: 460.0963\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.578\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -2678.610631578951 SOC: 0.9994 Cumulative_SOC_deviation: 297.6844 Fuel Consumption: 154.5088 Total Degradation: 447.1349\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.879\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -2010.2163767754032 SOC: 0.9837 Cumulative_SOC_deviation: 218.9777 Fuel Consumption: 153.4780 Total Degradation: 435.9092\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.305\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1495.6452974443316 SOC: 0.9398 Cumulative_SOC_deviation: 158.5352 Fuel Consumption: 151.4061 Total Degradation: 426.7868\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.974\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1975.9540307529765 SOC: 0.9291 Cumulative_SOC_deviation: 215.5277 Fuel Consumption: 148.4684 Total Degradation: 429.7263\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.048\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1974.6821527093632 SOC: 0.9594 Cumulative_SOC_deviation: 214.9304 Fuel Consumption: 152.2617 Total Degradation: 420.9034\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.021\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -949.2408441501672 SOC: 0.8353 Cumulative_SOC_deviation: 95.0155 Fuel Consumption: 143.5927 Total Degradation: 410.1479\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.150\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -1054.7769639240832 SOC: 0.8366 Cumulative_SOC_deviation: 107.4524 Fuel Consumption: 143.6752 Total Degradation: 398.0613\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.159\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -1042.342917435199 SOC: 0.8460 Cumulative_SOC_deviation: 105.8218 Fuel Consumption: 145.0668 Total Degradation: 404.7775\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.025\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -948.2402612847507 SOC: 0.8519 Cumulative_SOC_deviation: 94.6751 Fuel Consumption: 145.4791 Total Degradation: 403.9381\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.082\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -943.0357855114643 SOC: 0.6009 Cumulative_SOC_deviation: 96.2507 Fuel Consumption: 126.9145 Total Degradation: 387.3180\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.395\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -862.927352608319 SOC: 0.6497 Cumulative_SOC_deviation: 86.4322 Fuel Consumption: 130.0584 Total Degradation: 384.7950\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.386\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -1069.889732310273 SOC: 0.5493 Cumulative_SOC_deviation: 111.7245 Fuel Consumption: 122.5646 Total Degradation: 365.5870\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.323\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -1348.6472289819997 SOC: 0.5454 Cumulative_SOC_deviation: 144.6440 Fuel Consumption: 122.1935 Total Degradation: 376.0739\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.567\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -2086.764556606192 SOC: 0.3401 Cumulative_SOC_deviation: 233.4761 Fuel Consumption: 107.0924 Total Degradation: 328.9803\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.070\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1674.7691400039496 SOC: 0.4895 Cumulative_SOC_deviation: 183.4717 Fuel Consumption: 119.0908 Total Degradation: 346.8579\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.300\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -2395.7914907062222 SOC: 0.3572 Cumulative_SOC_deviation: 269.8415 Fuel Consumption: 107.7727 Total Degradation: 348.1643\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.353\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -2289.928476551201 SOC: 0.3585 Cumulative_SOC_deviation: 257.2859 Fuel Consumption: 108.3705 Total Degradation: 350.2685\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.405\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -2222.0749437134054 SOC: 0.3118 Cumulative_SOC_deviation: 249.6603 Fuel Consumption: 105.1751 Total Degradation: 333.5718\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.440\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -2806.9323169019704 SOC: 0.2418 Cumulative_SOC_deviation: 319.1690 Fuel Consumption: 100.6602 Total Degradation: 324.8314\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.620\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -2978.0312168211362 SOC: 0.2409 Cumulative_SOC_deviation: 339.3490 Fuel Consumption: 100.6499 Total Degradation: 329.4136\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.625\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -3752.332140358862 SOC: 0.1497 Cumulative_SOC_deviation: 431.2973 Fuel Consumption: 95.3104 Total Degradation: 328.6051\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.526\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -3324.1987288808987 SOC: 0.1836 Cumulative_SOC_deviation: 380.6733 Fuel Consumption: 96.4237 Total Degradation: 318.5683\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.701\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -4129.757378695261 SOC: 0.0515 Cumulative_SOC_deviation: 476.6180 Fuel Consumption: 88.4556 Total Degradation: 284.7998\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.714\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -3790.047455598542 SOC: 0.1189 Cumulative_SOC_deviation: 436.0869 Fuel Consumption: 92.4139 Total Degradation: 319.0161\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.586\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -2412.893252637739 SOC: 0.6095 Cumulative_SOC_deviation: 269.5706 Fuel Consumption: 127.1718 Total Degradation: 387.0482\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.398\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -216.98480792142576 SOC: 0.6066 Cumulative_SOC_deviation: 11.5120 Fuel Consumption: 119.3731 Total Degradation: 469.2664\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.611\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -197.5213225612824 SOC: 0.6154 Cumulative_SOC_deviation: 8.9640 Fuel Consumption: 121.5147 Total Degradation: 466.7737\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.772\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -173.85251655717602 SOC: 0.5972 Cumulative_SOC_deviation: 6.5529 Fuel Consumption: 118.2901 Total Degradation: 509.9545\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.747\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -177.6262845775195 SOC: 0.5966 Cumulative_SOC_deviation: 7.0223 Fuel Consumption: 118.0831 Total Degradation: 503.6939\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.736\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -181.4910172818543 SOC: 0.6198 Cumulative_SOC_deviation: 7.1734 Fuel Consumption: 120.6671 Total Degradation: 515.3473\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.880\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -185.3314310074883 SOC: 0.5919 Cumulative_SOC_deviation: 7.9786 Fuel Consumption: 117.6795 Total Degradation: 512.7857\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.557\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -190.98855056065602 SOC: 0.6002 Cumulative_SOC_deviation: 8.7169 Fuel Consumption: 117.0766 Total Degradation: 507.4411\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.222\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -203.18402281262541 SOC: 0.5898 Cumulative_SOC_deviation: 10.3667 Fuel Consumption: 115.2837 Total Degradation: 506.5343\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.725\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -232.56739251900007 SOC: 0.5989 Cumulative_SOC_deviation: 13.8183 Fuel Consumption: 115.4006 Total Degradation: 526.1365\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.565\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -233.4962717358384 SOC: 0.5943 Cumulative_SOC_deviation: 13.8354 Fuel Consumption: 116.1845 Total Degradation: 541.5007\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.573\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -233.81228419543584 SOC: 0.6006 Cumulative_SOC_deviation: 13.8959 Fuel Consumption: 115.9873 Total Degradation: 512.4178\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.690\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -202.3649524693884 SOC: 0.5956 Cumulative_SOC_deviation: 10.3295 Fuel Consumption: 114.7802 Total Degradation: 499.9329\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.891\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -220.36756822651 SOC: 0.5939 Cumulative_SOC_deviation: 12.4449 Fuel Consumption: 114.8458 Total Degradation: 502.0536\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.121\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -208.32564323477595 SOC: 0.5859 Cumulative_SOC_deviation: 11.1101 Fuel Consumption: 114.1218 Total Degradation: 509.4738\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.302\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -237.22914844561 SOC: 0.5943 Cumulative_SOC_deviation: 14.5534 Fuel Consumption: 113.8295 Total Degradation: 528.1351\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.131\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -252.59041716185118 SOC: 0.5958 Cumulative_SOC_deviation: 16.4174 Fuel Consumption: 113.3857 Total Degradation: 550.1809\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.727\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -269.067131157201 SOC: 0.5943 Cumulative_SOC_deviation: 18.3146 Fuel Consumption: 113.7756 Total Degradation: 555.5925\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.856\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -238.57993500623218 SOC: 0.5986 Cumulative_SOC_deviation: 14.7751 Fuel Consumption: 113.3001 Total Degradation: 556.4034\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.945\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -237.34439276038754 SOC: 0.5993 Cumulative_SOC_deviation: 14.6522 Fuel Consumption: 113.1070 Total Degradation: 550.5809\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.877\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -296.3010061668347 SOC: 0.5919 Cumulative_SOC_deviation: 21.7566 Fuel Consumption: 111.8240 Total Degradation: 555.5949\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.789\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -235.38528603368727 SOC: 0.5901 Cumulative_SOC_deviation: 14.4400 Fuel Consumption: 112.9468 Total Degradation: 539.8102\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.970\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -256.47480800736065 SOC: 0.5876 Cumulative_SOC_deviation: 16.9759 Fuel Consumption: 112.5344 Total Degradation: 532.3129\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.968\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -254.77005684874746 SOC: 0.5881 Cumulative_SOC_deviation: 16.8805 Fuel Consumption: 111.6379 Total Degradation: 531.4976\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.994\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -266.14820489649117 SOC: 0.5844 Cumulative_SOC_deviation: 18.4370 Fuel Consumption: 109.8190 Total Degradation: 548.9306\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.873\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -266.9402992885592 SOC: 0.5979 Cumulative_SOC_deviation: 18.2075 Fuel Consumption: 112.5566 Total Degradation: 549.3150\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.174\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -271.55942246226 SOC: 0.5873 Cumulative_SOC_deviation: 19.0001 Fuel Consumption: 110.4551 Total Degradation: 545.1805\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.342\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -286.03491449239795 SOC: 0.5896 Cumulative_SOC_deviation: 20.6119 Fuel Consumption: 111.2645 Total Degradation: 545.5870\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.215\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -267.2032179193144 SOC: 0.5888 Cumulative_SOC_deviation: 18.2739 Fuel Consumption: 112.2565 Total Degradation: 511.1258\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.013\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -274.75013550018633 SOC: 0.5823 Cumulative_SOC_deviation: 19.2987 Fuel Consumption: 111.1139 Total Degradation: 503.2272\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.988\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -288.6810472760716 SOC: 0.5899 Cumulative_SOC_deviation: 20.8440 Fuel Consumption: 111.9420 Total Degradation: 481.1894\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.971\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -264.0728175071768 SOC: 0.5840 Cumulative_SOC_deviation: 18.0297 Fuel Consumption: 111.1972 Total Degradation: 474.9549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.097\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -298.74467498155093 SOC: 0.5833 Cumulative_SOC_deviation: 22.2147 Fuel Consumption: 110.3837 Total Degradation: 503.2104\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.505\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -310.7524471602163 SOC: 0.5867 Cumulative_SOC_deviation: 23.6242 Fuel Consumption: 110.4396 Total Degradation: 543.4897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.366\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -256.90608847023026 SOC: 0.5845 Cumulative_SOC_deviation: 17.0618 Fuel Consumption: 112.2372 Total Degradation: 434.2014\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.268\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -245.42671502154815 SOC: 0.5832 Cumulative_SOC_deviation: 15.6522 Fuel Consumption: 112.7099 Total Degradation: 424.2873\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.179\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -313.9493333991366 SOC: 0.5872 Cumulative_SOC_deviation: 23.9541 Fuel Consumption: 110.8399 Total Degradation: 489.0873\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.064\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -200.46932714523848 SOC: 0.5871 Cumulative_SOC_deviation: 10.4818 Fuel Consumption: 111.5932 Total Degradation: 422.5868\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.135\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -313.31201275467237 SOC: 0.5785 Cumulative_SOC_deviation: 24.0479 Fuel Consumption: 109.4069 Total Degradation: 529.3473\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.991\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -324.7856484580742 SOC: 0.5916 Cumulative_SOC_deviation: 25.2061 Fuel Consumption: 111.0598 Total Degradation: 570.5097\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.388\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -324.15911176861647 SOC: 0.5826 Cumulative_SOC_deviation: 25.3573 Fuel Consumption: 109.1519 Total Degradation: 565.5066\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.366\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -290.7418760229118 SOC: 0.5910 Cumulative_SOC_deviation: 21.3213 Fuel Consumption: 109.9558 Total Degradation: 546.4096\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.424\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -273.93573607915556 SOC: 0.5840 Cumulative_SOC_deviation: 19.3670 Fuel Consumption: 109.7203 Total Degradation: 526.0210\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.342\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -338.22734360214383 SOC: 0.5825 Cumulative_SOC_deviation: 26.9256 Fuel Consumption: 109.9222 Total Degradation: 568.8361\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.193\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -360.229330039552 SOC: 0.5862 Cumulative_SOC_deviation: 29.5734 Fuel Consumption: 109.4729 Total Degradation: 570.8990\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.064\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -397.3554756029801 SOC: 0.5832 Cumulative_SOC_deviation: 33.9685 Fuel Consumption: 109.3326 Total Degradation: 568.3928\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.459\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -353.44389606333823 SOC: 0.5816 Cumulative_SOC_deviation: 28.7632 Fuel Consumption: 109.5569 Total Degradation: 567.1401\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.345\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -366.03925255978766 SOC: 0.5869 Cumulative_SOC_deviation: 30.3525 Fuel Consumption: 108.6766 Total Degradation: 571.3034\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.654\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -339.73647512890784 SOC: 0.5831 Cumulative_SOC_deviation: 27.0618 Fuel Consumption: 110.2761 Total Degradation: 559.6961\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.770\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -356.10751640734117 SOC: 0.5877 Cumulative_SOC_deviation: 29.1410 Fuel Consumption: 109.0177 Total Degradation: 571.3151\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.690\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -387.33826967448783 SOC: 0.5758 Cumulative_SOC_deviation: 32.8230 Fuel Consumption: 109.0280 Total Degradation: 567.5930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.003\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -326.2149931893057 SOC: 0.5904 Cumulative_SOC_deviation: 25.5340 Fuel Consumption: 109.7094 Total Degradation: 553.0486\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.881\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -176.29710027285023 SOC: 0.5985 Cumulative_SOC_deviation: 7.6385 Fuel Consumption: 111.5294 Total Degradation: 437.5181\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.552\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -163.60508199259493 SOC: 0.5891 Cumulative_SOC_deviation: 6.3569 Fuel Consumption: 109.7041 Total Degradation: 432.5562\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.347\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -196.4041854757918 SOC: 0.5948 Cumulative_SOC_deviation: 10.1159 Fuel Consumption: 110.6299 Total Degradation: 435.0408\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.532\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -174.23170373945277 SOC: 0.5927 Cumulative_SOC_deviation: 7.6943 Fuel Consumption: 108.9904 Total Degradation: 503.5956\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.074\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -154.38222094680458 SOC: 0.6012 Cumulative_SOC_deviation: 5.1909 Fuel Consumption: 110.3680 Total Degradation: 467.0487\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.093\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -258.1681321019468 SOC: 0.5940 Cumulative_SOC_deviation: 17.5274 Fuel Consumption: 109.5509 Total Degradation: 506.5367\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.282\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -207.47408566049236 SOC: 0.5834 Cumulative_SOC_deviation: 11.5564 Fuel Consumption: 109.4861 Total Degradation: 468.3283\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.282\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -245.45925054589418 SOC: 0.5880 Cumulative_SOC_deviation: 16.0210 Fuel Consumption: 109.6148 Total Degradation: 446.6529\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.136\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -281.05011436805023 SOC: 0.5897 Cumulative_SOC_deviation: 20.2080 Fuel Consumption: 109.7037 Total Degradation: 489.8861\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.320\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -234.06699884552273 SOC: 0.5951 Cumulative_SOC_deviation: 14.6440 Fuel Consumption: 109.8989 Total Degradation: 491.9350\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.617\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -212.34175296217597 SOC: 0.5883 Cumulative_SOC_deviation: 12.1462 Fuel Consumption: 109.3527 Total Degradation: 450.8331\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.692\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -192.50699641893962 SOC: 0.5896 Cumulative_SOC_deviation: 9.8482 Fuel Consumption: 109.0026 Total Degradation: 410.0731\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.793\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -216.91091217899668 SOC: 0.5891 Cumulative_SOC_deviation: 12.7807 Fuel Consumption: 108.5416 Total Degradation: 445.4022\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.550\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -194.4363340857807 SOC: 0.5907 Cumulative_SOC_deviation: 10.0615 Fuel Consumption: 109.1238 Total Degradation: 445.8424\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.682\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -200.62665096204424 SOC: 0.5937 Cumulative_SOC_deviation: 10.7997 Fuel Consumption: 109.0549 Total Degradation: 454.9676\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.034\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -208.9756211641989 SOC: 0.5940 Cumulative_SOC_deviation: 11.7994 Fuel Consumption: 108.9272 Total Degradation: 457.9139\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.063\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -215.8377959990872 SOC: 0.5911 Cumulative_SOC_deviation: 12.5541 Fuel Consumption: 109.3903 Total Degradation: 478.2255\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.822\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -193.1861456861776 SOC: 0.5914 Cumulative_SOC_deviation: 9.9478 Fuel Consumption: 108.8373 Total Degradation: 457.0721\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.535\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -211.46531159626093 SOC: 0.5901 Cumulative_SOC_deviation: 12.1049 Fuel Consumption: 108.8266 Total Degradation: 469.5333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.660\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -202.81589711271104 SOC: 0.5974 Cumulative_SOC_deviation: 11.0092 Fuel Consumption: 109.4677 Total Degradation: 509.0429\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.955\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -180.92636887739567 SOC: 0.5913 Cumulative_SOC_deviation: 8.5035 Fuel Consumption: 108.8244 Total Degradation: 492.4545\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.457\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -205.35117547403866 SOC: 0.5957 Cumulative_SOC_deviation: 11.3994 Fuel Consumption: 108.6939 Total Degradation: 501.9597\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.430\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -179.20168156970757 SOC: 0.5911 Cumulative_SOC_deviation: 8.3674 Fuel Consumption: 108.2532 Total Degradation: 508.9924\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.019\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -206.8389978729097 SOC: 0.5965 Cumulative_SOC_deviation: 11.5887 Fuel Consumption: 108.5772 Total Degradation: 502.3133\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.931\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -170.02466932746148 SOC: 0.5945 Cumulative_SOC_deviation: 7.2964 Fuel Consumption: 108.1576 Total Degradation: 522.7383\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.940\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -180.54233080909492 SOC: 0.5910 Cumulative_SOC_deviation: 8.5906 Fuel Consumption: 107.7014 Total Degradation: 524.7895\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.753\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -210.52358033628798 SOC: 0.5968 Cumulative_SOC_deviation: 12.0252 Fuel Consumption: 108.5600 Total Degradation: 511.0464\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.935\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -216.81801423993096 SOC: 0.5954 Cumulative_SOC_deviation: 12.8036 Fuel Consumption: 108.2550 Total Degradation: 568.8305\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.622\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -227.22066406044237 SOC: 0.5954 Cumulative_SOC_deviation: 14.0777 Fuel Consumption: 107.8541 Total Degradation: 571.7312\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.826\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -240.63867940660188 SOC: 0.5883 Cumulative_SOC_deviation: 15.7276 Fuel Consumption: 107.2824 Total Degradation: 555.1307\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.291\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -280.5784473908364 SOC: 0.5907 Cumulative_SOC_deviation: 20.4147 Fuel Consumption: 107.4794 Total Degradation: 545.9622\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.965\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -295.6553798171487 SOC: 0.5840 Cumulative_SOC_deviation: 22.2224 Fuel Consumption: 107.2292 Total Degradation: 555.9244\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.972\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -245.29222504242813 SOC: 0.5892 Cumulative_SOC_deviation: 16.1889 Fuel Consumption: 108.0248 Total Degradation: 547.6414\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.141\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -220.71541245349798 SOC: 0.5989 Cumulative_SOC_deviation: 13.2693 Fuel Consumption: 108.2032 Total Degradation: 539.7376\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.894\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -196.55439164524194 SOC: 0.5942 Cumulative_SOC_deviation: 10.4791 Fuel Consumption: 107.7007 Total Degradation: 549.2910\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.450\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -215.3591183717136 SOC: 0.5902 Cumulative_SOC_deviation: 12.6882 Fuel Consumption: 107.7743 Total Degradation: 526.0330\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.749\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -236.93321678625188 SOC: 0.5919 Cumulative_SOC_deviation: 15.2394 Fuel Consumption: 107.7163 Total Degradation: 531.8319\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.964\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -210.73882989585147 SOC: 0.5959 Cumulative_SOC_deviation: 12.1378 Fuel Consumption: 107.8208 Total Degradation: 548.8989\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.089\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -230.80565095050588 SOC: 0.5922 Cumulative_SOC_deviation: 14.4970 Fuel Consumption: 107.8839 Total Degradation: 553.4519\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.996\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -254.03140333032073 SOC: 0.5900 Cumulative_SOC_deviation: 17.2482 Fuel Consumption: 107.7818 Total Degradation: 556.7686\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.827\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -254.94821205298913 SOC: 0.5934 Cumulative_SOC_deviation: 17.3115 Fuel Consumption: 108.1620 Total Degradation: 562.9980\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.128\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -247.7961727001401 SOC: 0.5968 Cumulative_SOC_deviation: 16.4609 Fuel Consumption: 108.2224 Total Degradation: 570.4877\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.128\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -210.31513649147104 SOC: 0.5961 Cumulative_SOC_deviation: 12.0762 Fuel Consumption: 107.9200 Total Degradation: 565.9347\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.774\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -230.903136730953 SOC: 0.5908 Cumulative_SOC_deviation: 14.5314 Fuel Consumption: 107.6894 Total Degradation: 554.3322\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.014\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -250.1150278100356 SOC: 0.5929 Cumulative_SOC_deviation: 16.7145 Fuel Consumption: 108.3905 Total Degradation: 552.2108\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.886\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -245.9346685973831 SOC: 0.5906 Cumulative_SOC_deviation: 16.3207 Fuel Consumption: 107.5494 Total Degradation: 548.0715\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.745\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -212.02492588602482 SOC: 0.5910 Cumulative_SOC_deviation: 12.3155 Fuel Consumption: 107.6004 Total Degradation: 536.0389\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.983\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -190.49487746059359 SOC: 0.5971 Cumulative_SOC_deviation: 9.6323 Fuel Consumption: 108.8212 Total Degradation: 533.1503\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.015\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -232.92528536723557 SOC: 0.5949 Cumulative_SOC_deviation: 14.7340 Fuel Consumption: 107.9939 Total Degradation: 559.2844\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.049\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -309.3792540020245 SOC: 0.5749 Cumulative_SOC_deviation: 23.9416 Fuel Consumption: 106.3754 Total Degradation: 569.6579\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.934\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -232.0400650412901 SOC: 0.5988 Cumulative_SOC_deviation: 14.6959 Fuel Consumption: 107.4314 Total Degradation: 567.9839\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.192\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -155.33346561649086 SOC: 0.5970 Cumulative_SOC_deviation: 5.5813 Fuel Consumption: 108.0089 Total Degradation: 546.8449\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.902\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -197.99814603544334 SOC: 0.5990 Cumulative_SOC_deviation: 10.5991 Fuel Consumption: 108.1275 Total Degradation: 548.0427\n",
      "\n",
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "results_dict = {} \n",
    "reward_factor_temp = 2 \n",
    "consider_degradation = False \n",
    "\n",
    "driving_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "driving_cycle = sio.loadmat(driving_cycle_path)\n",
    "driving_cycle = driving_cycle[\"sch_cycle\"][:, 1]\n",
    "while True: \n",
    "    print(\"\")\n",
    "    print(\"reward factor = {}\".format(reward_factor_temp))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_train_history = []\n",
    "    for ep in range(total_episodes): \n",
    "        env = initialization_env(driving_cycle, reward_factor_temp, consider_degradation)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_train_history.append(env.history)\n",
    "        \n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        degradation_total = np.sum(np.array(env.history[\"degradation\"]))\n",
    "        print(\n",
    "            'Episode: {}'.format(ep + 1),\n",
    "            \"Exploration P: {:.4f}\".format(eps),\n",
    "            'Total reward: {}'.format(episodic_reward), \n",
    "            \"SOC: {:.4f}\".format(env.SOC), \n",
    "            \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "            \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "            \"Total Degradation: {:.4f}\".format(degradation_total)\n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "            \n",
    "    root = \"./noDegradation/reward_factor{}\".format(reward_factor_temp)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[reward_factor_temp] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"train_history\": episode_train_history \n",
    "    }\n",
    "    \n",
    "    reward_factor_temp, terminal = update_reward_factor(reward_factor_temp, \n",
    "                                                        results_dict[reward_factor_temp], \n",
    "                                                        0.015) \n",
    "    if terminal: \n",
    "        break \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"noDegradation_adaptive_reward_factor.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 0\n",
      "\n",
      "model is loaded on ./noDegradation/reward_factor2\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "WARNING:tensorflow:Layer batch_normalization_20 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 10.817\n",
      "Episode: 1 Exploration P: 0.5000 Total reward: -373.51163752987696 SOC: 0.6544 Cumulative_SOC_deviation: 42.6243 Fuel Consumption: 130.5532 Total Degradation: 382.7358\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 8.326\n",
      "Episode: 2 Exploration P: 0.5000 Total reward: -680.8466560998289 SOC: 0.7217 Cumulative_SOC_deviation: 99.5633 Fuel Consumption: 113.3359 Total Degradation: 303.5550\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 8.539\n",
      "Episode: 3 Exploration P: 0.5000 Total reward: -1228.0941782765929 SOC: 0.9285 Cumulative_SOC_deviation: 198.7176 Fuel Consumption: 95.4037 Total Degradation: 305.3011\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "WARNING:tensorflow:Layer batch_normalization_22 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 31.693\n",
      "Episode: 4 Exploration P: 0.4961 Total reward: -752.8423431012084 SOC: 0.6376 Cumulative_SOC_deviation: 99.4032 Fuel Consumption: 186.2438 Total Degradation: 549.8946\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.420\n",
      "Episode: 5 Exploration P: 0.4857 Total reward: -939.4788544844955 SOC: 0.8711 Cumulative_SOC_deviation: 148.3287 Fuel Consumption: 94.0055 Total Degradation: 298.6508\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 51.852\n",
      "Episode: 6 Exploration P: 0.4760 Total reward: -1271.0009179295596 SOC: 0.8903 Cumulative_SOC_deviation: 207.0912 Fuel Consumption: 90.5810 Total Degradation: 286.8125\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 30.324\n",
      "Episode: 7 Exploration P: 0.4705 Total reward: -279.68259387440116 SOC: 0.7253 Cumulative_SOC_deviation: 40.5033 Fuel Consumption: 48.8139 Total Degradation: 162.8137\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.235\n",
      "Episode: 8 Exploration P: 0.4623 Total reward: -261.21587197992983 SOC: 0.6571 Cumulative_SOC_deviation: 32.7621 Fuel Consumption: 74.4720 Total Degradation: 234.4038\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.821\n",
      "Episode: 9 Exploration P: 0.4490 Total reward: -1267.8910625442306 SOC: 0.7976 Cumulative_SOC_deviation: 199.1838 Fuel Consumption: 132.5435 Total Degradation: 395.9290\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 51.740\n",
      "Episode: 10 Exploration P: 0.4401 Total reward: -1018.608009413545 SOC: 0.8631 Cumulative_SOC_deviation: 163.1597 Fuel Consumption: 88.5977 Total Degradation: 278.4522\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 120.696\n",
      "Episode: 11 Exploration P: 0.4156 Total reward: -4218.158068179158 SOC: 0.8919 Cumulative_SOC_deviation: 704.5024 Fuel Consumption: 202.4944 Total Degradation: 738.4714\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.266\n",
      "Episode: 12 Exploration P: 0.3987 Total reward: -759.148409253416 SOC: 0.6864 Cumulative_SOC_deviation: 104.4150 Fuel Consumption: 163.9832 Total Degradation: 517.1831\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.827\n",
      "Episode: 13 Exploration P: 0.3788 Total reward: -1273.3576308512954 SOC: 0.7852 Cumulative_SOC_deviation: 189.0429 Fuel Consumption: 195.8129 Total Degradation: 619.2902\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.577\n",
      "Episode: 14 Exploration P: 0.3625 Total reward: -928.1146822454599 SOC: 0.4970 Cumulative_SOC_deviation: 135.8781 Fuel Consumption: 153.6092 Total Degradation: 504.6283\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.118\n",
      "Episode: 15 Exploration P: 0.3502 Total reward: -450.11815712713167 SOC: 0.5631 Cumulative_SOC_deviation: 58.3756 Fuel Consumption: 117.3774 Total Degradation: 381.6948\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.130\n",
      "Episode: 16 Exploration P: 0.3369 Total reward: -1813.5555485579919 SOC: 0.3444 Cumulative_SOC_deviation: 296.4118 Fuel Consumption: 124.0085 Total Degradation: 428.9542\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.744\n",
      "Episode: 17 Exploration P: 0.3265 Total reward: -1055.0700069152258 SOC: 0.4252 Cumulative_SOC_deviation: 167.9980 Fuel Consumption: 97.4815 Total Degradation: 328.3600\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.926\n",
      "Episode: 18 Exploration P: 0.3171 Total reward: -2066.0716376818946 SOC: 0.1378 Cumulative_SOC_deviation: 346.6164 Fuel Consumption: 90.3581 Total Degradation: 315.9709\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.904\n",
      "Episode: 19 Exploration P: 0.3082 Total reward: -1624.7096256823738 SOC: 0.2168 Cumulative_SOC_deviation: 270.6788 Fuel Consumption: 81.8407 Total Degradation: 285.0861\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Jumper_Brussels_101_1.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 110.517\n",
      "Episode: 20 Exploration P: 0.2929 Total reward: -2888.2317746577637 SOC: 0.2221 Cumulative_SOC_deviation: 481.5735 Fuel Consumption: 143.2629 Total Degradation: 515.1970\n",
      "\n",
      "battery power is 2864.800522021386(+) but condition is not avail\n",
      "******************* Test is start *****************\n",
      "Total reward: [-2343.84175294] SOC: -0.0003 Cumulative_SOC_deviation: 233.5855 Fuel Consumption: 15.8566 Degradation total: 23.3769\n",
      "******************* Test is done *****************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/driving_cycles/city\\VITO_RW_Kangoo_DePost_Brussels_101_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.718\n",
      "Episode: 21 Exploration P: 0.2781 Total reward: -3307.7639528011355 SOC: 0.1276 Cumulative_SOC_deviation: 554.8941 Fuel Consumption: 144.8678 Total Degradation: 481.1326\n",
      "\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.571\n",
      "Episode: 22 Exploration P: 0.2707 Total reward: -1232.19724541921 SOC: 0.3526 Cumulative_SOC_deviation: 203.0129 Fuel Consumption: 75.0236 Total Degradation: 259.8967\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "battery power is 9344.08275176345(+) but condition is not avail\n",
      "elapsed_time: 48.141\n",
      "Episode: 23 Exploration P: 0.2648 Total reward: [-3281.83926082] SOC: -0.0008 Cumulative_SOC_deviation: 388.9850 Fuel Consumption: 68.0498 Total Degradation: 210.7856\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:270: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:271: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.138\n",
      "Episode: 24 Exploration P: 0.2595 Total reward: -1607.9135357560488 SOC: 0.0977 Cumulative_SOC_deviation: 270.3143 Fuel Consumption: 67.1219 Total Degradation: 201.0121\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.351\n",
      "Episode: 25 Exploration P: 0.2541 Total reward: -538.5286499261831 SOC: 0.6308 Cumulative_SOC_deviation: 81.5491 Fuel Consumption: 73.6989 Total Degradation: 206.0879\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.651\n",
      "Episode: 26 Exploration P: 0.2451 Total reward: -1053.2936639527582 SOC: 0.3303 Cumulative_SOC_deviation: 155.7310 Fuel Consumption: 165.6272 Total Degradation: 490.3903\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.097\n",
      "Episode: 27 Exploration P: 0.2401 Total reward: -722.5410779683017 SOC: 0.2694 Cumulative_SOC_deviation: 118.2716 Fuel Consumption: 48.3929 Total Degradation: 169.8709\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.773\n",
      "Episode: 28 Exploration P: 0.2354 Total reward: -489.5920648374559 SOC: 0.4937 Cumulative_SOC_deviation: 75.3502 Fuel Consumption: 60.0957 Total Degradation: 248.3442\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 25.601\n",
      "Episode: 29 Exploration P: 0.2327 Total reward: -339.3552102493322 SOC: 0.4474 Cumulative_SOC_deviation: 54.7414 Fuel Consumption: 27.3291 Total Degradation: 132.3065\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 38.219\n",
      "Episode: 30 Exploration P: 0.2288 Total reward: -800.260645716621 SOC: 0.5466 Cumulative_SOC_deviation: 128.3779 Fuel Consumption: 68.5069 Total Degradation: 188.4217\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.303\n",
      "Episode: 31 Exploration P: 0.2224 Total reward: -1132.916527883816 SOC: 0.4370 Cumulative_SOC_deviation: 180.4256 Fuel Consumption: 104.4906 Total Degradation: 448.4602\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.653\n",
      "Episode: 32 Exploration P: 0.2180 Total reward: -230.09857358314173 SOC: 0.5905 Cumulative_SOC_deviation: 29.3032 Fuel Consumption: 63.0702 Total Degradation: 393.2747\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 125.181\n",
      "Episode: 33 Exploration P: 0.2062 Total reward: -301.5483254419082 SOC: 0.6160 Cumulative_SOC_deviation: 22.5107 Fuel Consumption: 173.2374 Total Degradation: 1225.0915\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.346\n",
      "Episode: 34 Exploration P: 0.1980 Total reward: -241.31478016366788 SOC: 0.6100 Cumulative_SOC_deviation: 16.7701 Fuel Consumption: 145.7250 Total Degradation: 886.9026\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.612\n",
      "Episode: 35 Exploration P: 0.1884 Total reward: -232.7801417268519 SOC: 0.5972 Cumulative_SOC_deviation: 11.5908 Fuel Consumption: 166.7127 Total Degradation: 1081.2189\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.897\n",
      "Episode: 36 Exploration P: 0.1805 Total reward: -214.1678935861051 SOC: 0.6047 Cumulative_SOC_deviation: 11.4604 Fuel Consumption: 148.8436 Total Degradation: 932.6682\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.263\n",
      "Episode: 37 Exploration P: 0.1746 Total reward: -162.63627465453447 SOC: 0.5955 Cumulative_SOC_deviation: 9.2262 Fuel Consumption: 110.0469 Total Degradation: 723.7886\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.420\n",
      "Episode: 38 Exploration P: 0.1681 Total reward: -1087.3981029095432 SOC: 0.4137 Cumulative_SOC_deviation: 169.4751 Fuel Consumption: 121.3901 Total Degradation: 770.2278\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.796\n",
      "Episode: 39 Exploration P: 0.1631 Total reward: -306.34314374827665 SOC: 0.5965 Cumulative_SOC_deviation: 36.0118 Fuel Consumption: 101.0759 Total Degradation: 662.2258\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.883\n",
      "Episode: 40 Exploration P: 0.1586 Total reward: -235.71269724485708 SOC: 0.5921 Cumulative_SOC_deviation: 21.9108 Fuel Consumption: 110.8211 Total Degradation: 614.9257\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "Total reward: -157.66937991131803 SOC: 0.5797 Cumulative_SOC_deviation: 17.1973 Fuel Consumption: 59.6450 Degradation total: 417.6774\n",
      "******************* Test is done *****************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.033\n",
      "Episode: 41 Exploration P: 0.1542 Total reward: -224.8549057428937 SOC: 0.6765 Cumulative_SOC_deviation: 20.9924 Fuel Consumption: 105.1981 Total Degradation: 582.8431\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Jumper_Brussels_101_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.495\n",
      "Episode: 42 Exploration P: 0.1468 Total reward: -1193.5622034377227 SOC: 0.6000 Cumulative_SOC_deviation: 181.4500 Fuel Consumption: 159.2973 Total Degradation: 1097.0088\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Kangoo_DePost_Brussels_101_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.061\n",
      "Episode: 43 Exploration P: 0.1397 Total reward: -665.2715255831063 SOC: 0.5923 Cumulative_SOC_deviation: 87.9815 Fuel Consumption: 163.7770 Total Degradation: 1106.2856\n",
      "\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.179\n",
      "Episode: 44 Exploration P: 0.1361 Total reward: -156.4779129064059 SOC: 0.5895 Cumulative_SOC_deviation: 12.6879 Fuel Consumption: 84.1567 Total Degradation: 584.3271\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.788\n",
      "Episode: 45 Exploration P: 0.1327 Total reward: -263.6328360887229 SOC: 0.6000 Cumulative_SOC_deviation: 26.0282 Fuel Consumption: 115.2722 Total Degradation: 520.6406\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.440\n",
      "Episode: 46 Exploration P: 0.1301 Total reward: -192.1279094123402 SOC: 0.5888 Cumulative_SOC_deviation: 16.1520 Fuel Consumption: 100.0616 Total Degradation: 353.0892\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.706\n",
      "Episode: 47 Exploration P: 0.1275 Total reward: -277.52367649864874 SOC: 0.4247 Cumulative_SOC_deviation: 39.4139 Fuel Consumption: 52.8645 Total Degradation: 399.6653\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.141\n",
      "Episode: 48 Exploration P: 0.1232 Total reward: -506.72514170951905 SOC: 0.5837 Cumulative_SOC_deviation: 58.3439 Fuel Consumption: 174.1648 Total Degradation: 714.9905\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.221\n",
      "Episode: 49 Exploration P: 0.1208 Total reward: -134.57887275602965 SOC: 0.5989 Cumulative_SOC_deviation: 11.7625 Fuel Consumption: 67.5325 Total Degradation: 397.5752\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 44.127\n",
      "Episode: 50 Exploration P: 0.1185 Total reward: -126.32438163466288 SOC: 0.6012 Cumulative_SOC_deviation: 10.8721 Fuel Consumption: 64.3535 Total Degradation: 380.0824\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 25.660\n",
      "Episode: 51 Exploration P: 0.1172 Total reward: -95.11296567849935 SOC: 0.5807 Cumulative_SOC_deviation: 10.5024 Fuel Consumption: 35.2491 Total Degradation: 202.9173\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 38.352\n",
      "Episode: 52 Exploration P: 0.1153 Total reward: -135.44796465235007 SOC: 0.6225 Cumulative_SOC_deviation: 11.9596 Fuel Consumption: 67.2781 Total Degradation: 216.6319\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.486\n",
      "Episode: 53 Exploration P: 0.1122 Total reward: -299.33194037934186 SOC: 0.4919 Cumulative_SOC_deviation: 33.8290 Fuel Consumption: 106.5067 Total Degradation: 471.1765\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.787\n",
      "Episode: 54 Exploration P: 0.1101 Total reward: -688.9530297599013 SOC: 0.6137 Cumulative_SOC_deviation: 108.7168 Fuel Consumption: 69.2670 Total Degradation: 370.0023\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 126.076\n",
      "Episode: 55 Exploration P: 0.1044 Total reward: -559.3969952481374 SOC: 0.5927 Cumulative_SOC_deviation: 67.9977 Fuel Consumption: 171.8100 Total Degradation: 1012.0347\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.092\n",
      "Episode: 56 Exploration P: 0.1005 Total reward: -747.4542201991784 SOC: 0.5230 Cumulative_SOC_deviation: 105.4071 Fuel Consumption: 146.6339 Total Degradation: 618.5799\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "battery power is 4556.04963138524(+) but condition is not avail\n",
      "elapsed_time: 65.760\n",
      "Episode: 57 Exploration P: 0.0978 Total reward: [-3331.88088793] SOC: -0.0000 Cumulative_SOC_deviation: 397.6767 Fuel Consumption: 68.5444 Total Degradation: 300.7629\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "battery power is 3837.3495815415054(+) but condition is not avail\n",
      "elapsed_time: 30.475\n",
      "Episode: 58 Exploration P: 0.0965 Total reward: [-2335.17537624] SOC: -0.0007 Cumulative_SOC_deviation: 232.8581 Fuel Consumption: 11.3088 Total Degradation: 60.1010\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.666\n",
      "Episode: 59 Exploration P: 0.0935 Total reward: -2296.7247216331843 SOC: 0.5416 Cumulative_SOC_deviation: 382.6301 Fuel Consumption: 115.7332 Total Degradation: 471.4265\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.246\n",
      "Episode: 60 Exploration P: 0.0902 Total reward: -1131.6644512253074 SOC: 0.4851 Cumulative_SOC_deviation: 174.9695 Fuel Consumption: 134.3385 Total Degradation: 682.6823\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:270: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:271: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "Total reward: -723.7435595122517 SOC: 0.4681 Cumulative_SOC_deviation: 117.7424 Fuel Consumption: 52.6117 Degradation total: 367.4071\n",
      "******************* Test is done *****************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.241\n",
      "Episode: 61 Exploration P: 0.0877 Total reward: -384.3626719695122 SOC: 0.5789 Cumulative_SOC_deviation: 49.0465 Fuel Consumption: 104.7974 Total Degradation: 525.1290\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.034\n",
      "Episode: 62 Exploration P: 0.0854 Total reward: -436.8603554915184 SOC: 0.5680 Cumulative_SOC_deviation: 54.9554 Fuel Consumption: 123.6146 Total Degradation: 482.5049\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.080\n",
      "Episode: 63 Exploration P: 0.0832 Total reward: -291.73137536960877 SOC: 0.5732 Cumulative_SOC_deviation: 32.6951 Fuel Consumption: 105.3693 Total Degradation: 432.0296\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Jumper_Brussels_101_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.549\n",
      "Episode: 64 Exploration P: 0.0794 Total reward: -889.1518920797521 SOC: 0.5346 Cumulative_SOC_deviation: 128.0327 Fuel Consumption: 159.3655 Total Degradation: 901.5002\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Kangoo_DePost_Brussels_101_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.356\n",
      "Episode: 65 Exploration P: 0.0758 Total reward: -993.2682494532064 SOC: 0.5699 Cumulative_SOC_deviation: 144.2646 Fuel Consumption: 170.9600 Total Degradation: 846.3642\n",
      "\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.322\n",
      "Episode: 66 Exploration P: 0.0740 Total reward: -393.92619189830435 SOC: 0.5366 Cumulative_SOC_deviation: 54.7926 Fuel Consumption: 81.6083 Total Degradation: 494.1742\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:270: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:271: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.975\n",
      "Episode: 67 Exploration P: 0.0722 Total reward: -1226.4773307723428 SOC: 0.5480 Cumulative_SOC_deviation: 192.4911 Fuel Consumption: 129.2779 Total Degradation: 379.2866\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.509\n",
      "Episode: 68 Exploration P: 0.0709 Total reward: -959.511771687895 SOC: 0.5575 Cumulative_SOC_deviation: 150.3578 Fuel Consumption: 102.4725 Total Degradation: 313.4761\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.691\n",
      "Episode: 69 Exploration P: 0.0696 Total reward: -344.0262045072501 SOC: 0.5328 Cumulative_SOC_deviation: 49.2621 Fuel Consumption: 63.2320 Total Degradation: 271.2318\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.196\n",
      "Episode: 70 Exploration P: 0.0674 Total reward: -1118.0915545362243 SOC: 0.5446 Cumulative_SOC_deviation: 163.7039 Fuel Consumption: 184.9795 Total Degradation: 444.6547\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.361\n",
      "Episode: 71 Exploration P: 0.0662 Total reward: -281.72595823443913 SOC: 0.5610 Cumulative_SOC_deviation: 37.5526 Fuel Consumption: 67.6760 Total Degradation: 284.5251\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 44.146\n",
      "Episode: 72 Exploration P: 0.0651 Total reward: -320.65664377618754 SOC: 0.5226 Cumulative_SOC_deviation: 45.7760 Fuel Consumption: 59.7333 Total Degradation: 351.3839\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 25.681\n",
      "Episode: 73 Exploration P: 0.0644 Total reward: -284.1177164354542 SOC: 0.5217 Cumulative_SOC_deviation: 43.9902 Fuel Consumption: 33.3736 Total Degradation: 163.4365\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 38.457\n",
      "Episode: 74 Exploration P: 0.0634 Total reward: -240.69728955267757 SOC: 0.5990 Cumulative_SOC_deviation: 29.9290 Fuel Consumption: 70.1020 Total Degradation: 241.1309\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.486\n",
      "Episode: 75 Exploration P: 0.0619 Total reward: -211.76333731725728 SOC: 0.5658 Cumulative_SOC_deviation: 17.2648 Fuel Consumption: 113.3541 Total Degradation: 443.3850\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.848\n",
      "Episode: 76 Exploration P: 0.0608 Total reward: -275.6613910754772 SOC: 0.5521 Cumulative_SOC_deviation: 37.0387 Fuel Consumption: 64.5408 Total Degradation: 316.9155\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 126.111\n",
      "Episode: 77 Exploration P: 0.0579 Total reward: -755.1987217855086 SOC: 0.5300 Cumulative_SOC_deviation: 102.7136 Fuel Consumption: 169.7312 Total Degradation: 893.0343\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.029\n",
      "Episode: 78 Exploration P: 0.0559 Total reward: -802.0939932070626 SOC: 0.5502 Cumulative_SOC_deviation: 113.0123 Fuel Consumption: 157.9237 Total Degradation: 499.7142\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.141\n",
      "Episode: 79 Exploration P: 0.0536 Total reward: -1195.7322188185583 SOC: 0.4518 Cumulative_SOC_deviation: 179.2825 Fuel Consumption: 173.8222 Total Degradation: 660.1874\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.126\n",
      "Episode: 80 Exploration P: 0.0516 Total reward: -911.7062804914292 SOC: 0.6023 Cumulative_SOC_deviation: 130.8128 Fuel Consumption: 166.0731 Total Degradation: 596.4766\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "Total reward: -104.38945810873514 SOC: 0.6020 Cumulative_SOC_deviation: 4.6481 Fuel Consumption: 77.8955 Degradation total: 268.9018\n",
      "******************* Test is done *****************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.691\n",
      "Episode: 81 Exploration P: 0.0502 Total reward: -332.67218856164453 SOC: 0.5605 Cumulative_SOC_deviation: 38.2485 Fuel Consumption: 114.6560 Total Degradation: 489.4052\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.826\n",
      "Episode: 82 Exploration P: 0.0486 Total reward: -604.5059832882698 SOC: 0.5154 Cumulative_SOC_deviation: 81.8579 Fuel Consumption: 137.9161 Total Degradation: 542.6006\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.293\n",
      "Episode: 83 Exploration P: 0.0474 Total reward: -1402.4772975701653 SOC: 0.5074 Cumulative_SOC_deviation: 227.8285 Fuel Consumption: 103.8550 Total Degradation: 471.4817\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.073\n",
      "Episode: 84 Exploration P: 0.0463 Total reward: -1034.3255939559685 SOC: 0.4764 Cumulative_SOC_deviation: 159.7465 Fuel Consumption: 123.7705 Total Degradation: 340.2461\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.349\n",
      "Episode: 85 Exploration P: 0.0452 Total reward: -946.3128643679173 SOC: 0.5167 Cumulative_SOC_deviation: 147.4244 Fuel Consumption: 105.9936 Total Degradation: 391.1947\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Jumper_Brussels_101_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.542\n",
      "Episode: 86 Exploration P: 0.0434 Total reward: -1187.138912230979 SOC: 0.5361 Cumulative_SOC_deviation: 179.6613 Fuel Consumption: 163.0695 Total Degradation: 819.9169\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Kangoo_DePost_Brussels_101_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.224\n",
      "Episode: 87 Exploration P: 0.0417 Total reward: -1117.5172889774985 SOC: 0.5886 Cumulative_SOC_deviation: 165.3709 Fuel Consumption: 174.9030 Total Degradation: 776.4292\n",
      "\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.504\n",
      "Episode: 88 Exploration P: 0.0408 Total reward: -236.2768291711129 SOC: 0.5697 Cumulative_SOC_deviation: 26.5599 Fuel Consumption: 84.8855 Total Degradation: 495.4273\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.714\n",
      "Episode: 89 Exploration P: 0.0400 Total reward: -319.91331981296986 SOC: 0.5775 Cumulative_SOC_deviation: 33.9072 Fuel Consumption: 126.6425 Total Degradation: 378.5947\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.434\n",
      "Episode: 90 Exploration P: 0.0393 Total reward: -255.72088517772286 SOC: 0.5616 Cumulative_SOC_deviation: 26.9108 Fuel Consumption: 102.3295 Total Degradation: 332.3832\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.718\n",
      "Episode: 91 Exploration P: 0.0387 Total reward: -218.06364773873 SOC: 0.5722 Cumulative_SOC_deviation: 26.7140 Fuel Consumption: 65.7938 Total Degradation: 339.0575\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:270: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_degradation\\DDPG_adaptive_rewardfactor_final\\vehicle_model_variant.py:271: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.321\n",
      "Episode: 92 Exploration P: 0.0376 Total reward: -1864.8500747899839 SOC: 0.2529 Cumulative_SOC_deviation: 299.7234 Fuel Consumption: 156.4264 Total Degradation: 517.0758\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.243\n",
      "Episode: 93 Exploration P: 0.0371 Total reward: -984.6405236266983 SOC: 0.5165 Cumulative_SOC_deviation: 161.1144 Fuel Consumption: 66.2886 Total Degradation: 271.1596\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 44.018\n",
      "Episode: 94 Exploration P: 0.0365 Total reward: -336.49530564829416 SOC: 0.5787 Cumulative_SOC_deviation: 47.6365 Fuel Consumption: 64.9673 Total Degradation: 322.3704\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 25.595\n",
      "Episode: 95 Exploration P: 0.0362 Total reward: -166.25650525197085 SOC: 0.5639 Cumulative_SOC_deviation: 22.8868 Fuel Consumption: 35.8020 Total Degradation: 176.3547\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 38.365\n",
      "Episode: 96 Exploration P: 0.0357 Total reward: -161.2009649096459 SOC: 0.5919 Cumulative_SOC_deviation: 16.1902 Fuel Consumption: 68.9169 Total Degradation: 255.7519\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.575\n",
      "Episode: 97 Exploration P: 0.0350 Total reward: -205.62142754391866 SOC: 0.6402 Cumulative_SOC_deviation: 14.7226 Fuel Consumption: 121.7024 Total Degradation: 381.4426\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.909\n",
      "Episode: 98 Exploration P: 0.0345 Total reward: -137.04901857583707 SOC: 0.5857 Cumulative_SOC_deviation: 12.5402 Fuel Consumption: 65.5697 Total Degradation: 301.4936\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 125.902\n",
      "Episode: 99 Exploration P: 0.0331 Total reward: -2009.5813204972644 SOC: 0.5909 Cumulative_SOC_deviation: 322.1264 Fuel Consumption: 173.4606 Total Degradation: 899.1097\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.181\n",
      "Episode: 100 Exploration P: 0.0321 Total reward: -2032.124208141012 SOC: 0.4253 Cumulative_SOC_deviation: 332.0685 Fuel Consumption: 139.3338 Total Degradation: 558.8812\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "Total reward: -961.7126067634965 SOC: 0.4232 Cumulative_SOC_deviation: 158.7360 Fuel Consumption: 56.9176 Degradation total: 308.0332\n",
      "******************* Test is done *****************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "# print(env.version)\n",
    "\n",
    "num_trials = 1\n",
    "total_episodes = 100 \n",
    "MAX_EPSILON = 0.5 \n",
    "\n",
    "results_dict = {} \n",
    "driving_cycle_paths = glob.glob(\"../data/driving_cycles/city/*.mat\")\n",
    "reward_factor_opt = 5.7\n",
    "\n",
    "\n",
    "for trial in range(num_trials): \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(trial))\n",
    "    print(\"\")\n",
    "    \n",
    "    weights_root = \"./noDegradation/reward_factor2\"\n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization(weights_root)\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = []\n",
    "    episode_train_history = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes):\n",
    "        i = ep % len(driving_cycle_paths)\n",
    "        driving_cycle_path =driving_cycle_paths[i]\n",
    "        print(driving_cycle_path)\n",
    "        drv_cycle = sio.loadmat(driving_cycle_path)\n",
    "        driving_cycle = drv_cycle[\"sch_cycle\"][:, 1]\n",
    "\n",
    "        env = initialization_env(driving_cycle, reward_factor_opt, consider_degradation)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_train_history.append(env.history)\n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        degradation_total = np.sum(np.array(env.history[\"degradation\"]))\n",
    "        print(\n",
    "            'Episode: {}'.format(ep + 1),\n",
    "            \"Exploration P: {:.4f}\".format(eps),\n",
    "            'Total reward: {}'.format(episodic_reward), \n",
    "            \"SOC: {:.4f}\".format(env.SOC), \n",
    "            \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "            \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "            \"Total Degradation: {:.4f}\".format(degradation_total)\n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 20 == 0: \n",
    "            history = test_agent(actor_model, reward_factor_opt, consider_degradation)\n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "            \n",
    "          \n",
    "    root = \"./noDegradation/models_final\"\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"train_history\": episode_train_history, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"noDegradation_adaptive_reward_factor_finalModel.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
